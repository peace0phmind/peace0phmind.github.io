<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Machine Learning</title><url>/posts/202211/01-machine-learning/</url><categories><category>machine-learning</category></categories><tags><tag><no value=/></tags><content type="html"> Machine Learning是什么 简单的理解就是在输入和输出中找一个函数
Different types of Functions Deep Learning Introduce history (Ups and downs of Deep Learning) 1958: Perceptron (linear model) 1969: Perceptron has limitation 1980: Multi-layer perceptron Do not have significant difference from DNN today 1986: Backpropagation Usually more than 3 hidden layers is not helpful 1989: 1 hidden layer is &amp;ldquo;good enough&amp;rdquo;, why deep? 2006: RBM initialization (breakthrough) 2009: GPU 2011: Start to be popular in speech recognition 2012: win ILSVRC image competition Fully Connect Feedforward Network 输入叫Input Layer 输出叫Output Layer 中间层叫hidden Layers Fully Connect Feedforward Network Deep = Many hidden layers AlexNet(2012), 8 layers, error rate: 16.4% VGG(2014), 19 layers, error rate: 7.3% GoogleNet(2014), 22 layers, error rate: 6.7% Residual Net(2015), 152 layers, error rate: 3.57% FAQ Q: How many layers? How many neurons for each layer? Trial and Error + Intuition Q: Can the structure be automatically determined? Evolutionary Artificial Neural Networks Q: Can we design the network structure? Convolutional Neural Network (CNN) Q: Deeper is Better? Universality Theorem Any continuous function f $ f : R^N \rightarrow R^M $ Can be realized by a network with one hidden layer (given enough hidden neurons) Why Deep neural network not Fat neural network? Reference 系列文档是国立台湾大学 李宏毅 老师Machine Learning系列教材的学习整理。
Machine Learning 2022 Machine Learning 2021 Machine Learning 2020 Machine Learning 2019 Machine Learning 2018 Machine Learning 2016 FALL MLDS 2015 FALL Reference Video Nvidia Resources nvidia training resource Reference Book Neural Networks and Deep Learning written by Michael Nielsen Deep Learning written by Yoshua Bengio, Ian J. Goodfellow and Aaron Courville</content></entry><entry><title>latex公式</title><url>/posts/202211/latex-formula/</url><categories><category>blog</category></categories><tags><tag>latex</tag><tag>formula</tag></tags><content type="html"><![CDATA[Use $\Sigma$ in different mode sum mode making-the-subscript-under-the-summation use color Using_colours_in_LaTeX inline math $\sum_{i=1}^{\infty}|x_i-y_i|$ $\sum_{i=1}^{\infty}|x_i-y_i|$
display math $$ \sum_{i=1}^{\infty}|x_i-y_i| $$ $$ \sum_{i=1}^{\infty}|x_i-y_i| $$
use \limits $\sum\limits_{i=1}^{\infty}|x_i-y_i|$ $\sum\limits_{i=1}^{\infty}|x_i-y_i|$
use color ${\color{red}\eta}\frac{{\delta}L}{{\delta}W}|_{w=w^0}$ ${\color{red}\eta}\frac{{\delta}L}{{\delta}W}|_{w=w^0}$
frac and sfrac $ \frac{1}{2} = \sfrac{1}{2} $ $ \frac{1}{2} = \sfrac{1}{2} $
text and textcolor $\textcolor{red}{\text{red curve}}\text{ will be}$ $\textcolor{red}{\text{red curve}}\text{ will be}$
cases $$ \delta(x) = \begin{cases} g(x) &gt; 0 &amp; \text{Output = class 1} \cr else &amp; \text{Output = class 2} \end{cases} $$ $$ \delta(x) = \begin{cases}
g(x) &gt; 0 &amp; \text{Output = class 1} \cr else &amp; \text{Output = class 2} \end{cases} $$
newline, space, align and tag new line use \cr or \\\\ space use \\,, \quad align use \begin{align}, \end{align} and &amp; tag use \tag{1}, or use ams automatic , equation-numbers tag with ams automatic, will omit by \notag or block symbol end with *, for example: \begin{align*}, \end{align*} use \begin{align} and \end{align} instead of $$ or $ \begin{align} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\\\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\\,b\tag{xyz} \end{align} \begin{align} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\,b\tag{xyz} \end{align}
\begin{align*} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\\\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\\,b\tag{xyz} \end{align*} \begin{align*} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\,b\tag{xyz} \end{align*}
matrices Matrices Type Latex markup Render as Plain \begin{matrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{matrix} \begin{matrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{matrix} Parentheses; round brackets \begin{pmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{pmatrix} \begin{pmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{pmatrix} Brackets; square brackets \begin{bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{bmatrix} \begin{bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{bmatrix} Braces; curly brackets \begin{Bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Bmatrix} \begin{Bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Bmatrix} Pipes \begin{vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{vmatrix} \begin{vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{vmatrix} Double pipes \begin{Vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Vmatrix} \begin{Vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Vmatrix} block symbol: equation, split, multline, gather, align equation equation can only include one equation or it will not render \begin{equation} x=y \end{equation} \begin{equation} x=y \end{equation}
\begin{equation} x=y \cr y=b \end{equation} \begin{equation} x=y \cr y=b \end{equation}
split split can use with equation but the tag was only one \begin{equation} \begin{split} x=y \cr y=b \end{split} \end{equation} \begin{equation} \begin{split} x=y \cr y=b \end{split} \end{equation}
multline multline same as equation with split but with different align \begin{multline} x=y \cr y=b \end{multline} \begin{multline} x=y \cr y=b \end{multline}
gather \begin{gather} x=y \cr y=b \end{gather} \begin{gather} x=y \cr y=b \end{gather}
align \begin{align} x=y \cr y=b \end{align} \begin{align} x=y \cr y=b \end{align}
参考 Classical ML Equations in LaTeX ]]></content></entry><entry><title>latex符号</title><url>/posts/202211/latex-symbols.html</url><categories><category>blog</category></categories><tags><tag>latex</tag><tag>symbol</tag></tags><content type="html"><![CDATA[reference MathJax LaTex Ref LaTex Math Symbols or LaTex Math Symbols LaTeX_mathematical_symbols short-math-guide or short-math-guide spaces in markdown Regular space : There&#39;s a regular&amp;nbsp;space. Two spaces gap : There&#39;s a regular&amp;ensp;space. Four spaces gap: There&#39;s a regular&amp;emsp;space. There&rsquo;s a regular space. There&rsquo;s a regular space. There&rsquo;s a regular space. Math Mode Accents $\hat{a}$ \hat{a} $\check{a}$ \check{a} $\tilde{a}$ \tilde{a} $\acute{a}$ \acute{a} $\grave{a}$ \grave{a} $\dot{a}$ \dot{a} $\ddot{a}$ \ddot{a} $\breve{a}$ \breve{a} $\bar{a}$ \bar{a} $\vec{a}$ \vec{a} $\widehat{A}$ \widehat{A} $\widetilde{A}$ \widetilde{A} Greek Letters alpha, beta, gamma, delta, epsilon, zeta, eta, theta, iota, kappa, lambda, mu, nu, xi, omicron, pi, rho, sigma, tau, upsilon, phi, chi, psi, omega.
$\alpha$ \alpha $\beta$ \beta $\Gamma$ $\gamma$ \Gamma \gamma $\Delta$ $\delta$ \Delta \delta $\epsilon$ $\varepsilon$ \epsilon \varepsilon $\zeta$ \zeta $\eta$ \eta $\Theta$ $\theta$ $\vartheta$ \Theta \theta \vartheta $\iota$ \iota $\kappa$ \kappa $\Lambda$ $\lambda$ \Lambda \lambda $\mu$ \mu $\nu$ \nu $\Xi$ $\xi$ \Xi \xi $o$ o (omicron) $\Pi$ $\pi$ $\varpi$ \Pi \pi \varpi $\rho$ $\varrho$ \rho \varrho $\Sigma$ $\sigma$ $\varsigma$ \Sigma \sigma \varsigma $\tau$ \tau $\Upsilon$ $\upsilon$ \Upsilon \upsilon $\Phi$ $\phi$ $\varphi$ \Phi \phi \varphi $\chi$ \chi $\Psi$ $\psi$ \Psi \psi $\Omega$ $\omega$ \Omega \omega Arrows $\leftarrow$ \leftarrow or \gets $\rightarrow$ \rightarrow or \to $\leftrightarrow$ \leftrightarrow $\Leftarrow$ \Leftarrow $\Rightarrow$ \Rightarrow $\Leftrightarrow$ \Leftrightarrow $\longleftarrow$ \longleftarrow $\longrightarrow$ \longrightarrow $\longleftrightarrow$ \longleftrightarrow $\Longleftarrow$ \Longleftarrow $\Longrightarrow$ \Longrightarrow $\Longleftrightarrow$ \Longleftrightarrow or \iff $\uparrow$ \uparrow $\downarrow$ \downarrow $\updownarrow$ \updownarrow $\Uparrow$ \Uparrow $\Downarrow$ \Downarrow $\Updownarrow$ \Updownarrow $\mapsto$ \mapsto $\longmapsto$ \longmapsto $\multimap$ \multimap $\hookleftarrow$ \hookleftarrow $\hookrightarrow$ \hookrightarrow $\upharpoonleft$ \upharpoonleft $\leftharpoonup$ \leftharpoonup $\rightharpoonup$ \rightharpoonup $\upharpoonright$ \upharpoonright $\leftharpoondown$ \leftharpoondown $\rightharpoondown$ \rightharpoondown $\downharpoonleft$ \downharpoonleft $\leftrightharpoons$ \leftrightharpoons $\rightleftharpoons$ \rightleftharpoons $\downharpoonright$ \downharpoonright $\leftleftarrows$ \leftleftarrows $\rightrightarrows$ \rightrightarrows $\upuparrows$ \upuparrows $\leftrightarrows$ \leftrightarrows $\rightleftarrows$ \rightleftarrows $\downdownarrows$ \downdownarrows $\dashleftarrow$ \dashleftarrow $\dashrightarrow$ \dashrightarrow $\nearrow$ \nearrow $\twoheadleftarrow$ \twoheadleftarrow $\twoheadrightarrow$ \twoheadrightarrow $\searrow$ \searrow $\leftarrowtail$ \leftarrowtail $\rightarrowtail$ \rightarrowtail $\swarrow$ \swarrow $\Lsh$ \Lsh $\Rsh$ \Rsh $\nwarrow$ \nwarrow $\Lleftarrow$ \Lleftarrow $\Rrightarrow$ \Rrightarrow $\rightsquigarrow$ \rightsquigarrow or \leadsto $\looparrowleft$ \looparrowleft $\looparrowright$ \looparrowright $\leftrightsquigarrow$ \leftrightsquigarrow $\curvearrowleft$ \curvearrowleft $\curvearrowright$ \curvearrowright $\circlearrowleft$ \circlearrowleft $\circlearrowright$ \circlearrowright arrow-latex Miscellaneous Symbols $\dots$ \dots $\cdots$ \cdots $\vdots$ \vdots $\ddots$ \ddots $\hbar$ \hbar $\imath$ \imath $\jmath$ \jmath $\ell$ \ell $\Re$ \Re $\Im$ \Im $\aleph$ \aleph $\wp$ \wp $\forall$ \forall $\exists$ \exists $\mho$ \mho $\partial$ \partial $&rsquo;$ ' $\prime$ \prime $\emptyset$ \emptyset $\infty$ \infty $\nabla$ \nabla $\triangle$ \triangle $\Box$ \Box $\Diamond$ \Diamond $\bot$ \bot $\top$ \top $\angle$ \angle $\surd$ \surd $\diamondsuit$ \diamondsuit $\heartsuit$ \heartsuit $\clubsuit$ \clubsuit $\spadesuit$ \spadesuit $\neg$ \neg or \lnot $\flat$ \flat $\natural$ \natural $\sharp$ \sharp delimiters $($ ( $)$ ) $\lbrack$ [ or \lbrack $\rbrack$ ] or \rbrack $\lbrace$ \\{ or \lbrace $\rbrace$ \\} or \rbrace $\langle$ \langle $\rangle$ \rangle $/$ / $\backslash$ \backslash $\vert$ \vert or | $\Vert$ \Vert or \\| $\lfloor$ \lfloor $\rfloor$ \rfloor $\lceil$ \lceil $\rceil$ \rceil Binary Relations $&lt;$ &lt; $&gt;$ &gt; $=$ = $\leq$ \leq or \le $\geq$ \geq or \ge $\equiv$ \equiv $\ll$ \ll $\gg$ \gg $\doteq$ \doteq $\prec$ \prec $\succ$ \succ $\sim$ \sim $\preceq$ \preceq $\succeq$ \succeq $\simeq$ \simeq $\subset$ \subset $\supset$ \supset $\approx$ \approx $\subseteq$ \subseteq $\supseteq$ \supseteq $\cong$ \cong $\sqsubset$ \sqsubset $\sqsupset$ \sqsupset $\Join$ \Join $\sqsubseteq$ \sqsubseteq $\sqsupseteq$ \sqsupseteq $\bowtie$ \bowtie $\in$ \in $\ni$ \ni or \owns $\propto$ \propto $\vdash$ \vdash $\dashv$ \dashv $\models$ \models $\mid$ \mid $\parallel$ \parallel $\perp$ \perp $\smile$ \smile $\frown$ \frown $\asymp$ \asymp $:$ : $\notin$ \notin $\ne$ \neq or \ne Binary Operators $\pm$ \pm $\mp$ \mp $\triangleleft$ \triangleleft $\cdot$ \cdot $\div$ \div $\triangleright$ \triangleright $\times$ \times $\setminus$ \setminus $\star$ \star $\cup$ \cup $\cap$ \cap $\ast$ \ast $\sqcup$ \sqcup $\sqcap$ \sqcap $\circ$ \circ $\vee$ \vee, \lor $\land$ \wedge, \land $\bullet$ \bullet $\oplus$ \oplus $\ominus$ \ominus $\diamond$ \diamond $\odot$ \odot $\oslash$ \oslash $\uplus$ \uplus $\otimes$ \otimes $\bigcirc$ \bigcirc $\amalg$ \amalg $\bigtriangleup$ \bigtriangleup $\bigtriangledown$ \bigtriangledown $\dagger$ \dagger $\lhd$ \lhd $\rhd$ \rhd $\ddagger$ \ddagger $\unlhd$ \unlhd $\unrhd$ \unrhd $\wr$ \wr AMS Miscellaneous $\hbar$ \hbar $\hslash$ \hslash $\Bbbk$ \Bbbk $\square$ \square $\blacksquare$ \blacksquare $\circledS$ \circledS $\vartriangle$ \vartriangle $\blacktriangle$ \blacktriangle $\complement$ \complement $\triangledown$ \triangledown $\blacktriangledown$ \blacktriangledown $\Game$ \Game $\lozenge$ \lozenge $\blacklozenge$ \blacklozenge $\bigstar$ \bigstar $\angle$ \angle $\measuredangle$ \measuredangle $\sphericalangle$ \sphericalangle $\diagup$ \diagup $\diagdown$ \diagdown $\backprime$ \backprime $\nexists$ \nexists $\Finv$ \Finv $\varnothing$ \varnothing $\eth$ \eth $\mho$ \mho bold fonts For those symbols where \mathbf is not applicable, the \boldsymbol or \pmb commands can be used.
A_\infty + \pi A_0 \sim \mathbf{A}_{\boldsymbol{\infty}} \boldsymbol{+} \boldsymbol{\pi} \mathbf{A}_{\boldsymbol{0}} \sim\pmb{A}_{\pmb{\infty}} \pmb{+}\pmb{\pi} \pmb{A}_{\pmb{0}} $$ A_\infty &#43; \pi A_0 \sim \mathbf{A}_{\boldsymbol{\infty}} \boldsymbol{&#43;} \boldsymbol{\pi} \mathbf{A}_{\boldsymbol{0}} \sim\pmb{A}_{\pmb{\infty}} \pmb{&#43;}\pmb{\pi} \pmb{A}_{\pmb{0}} $$]]></content></entry><entry><title>Latex Colors</title><url>/posts/202211/latex-colors/</url><categories><category>blog</category></categories><tags><tag>latex</tag><tag>colors</tag></tags><content type="html">常用颜色 $\color{Red}\blacksquare$ Red $\color{Green}\blacksquare$ Green $\color{Blue}\blacksquare$ Blue $\color{Cyan}\blacksquare$ Cyan $\color{Magenta}\blacksquare$ Magenta $\color{Yellow}\blacksquare$ Yellow $\color{Black}\blacksquare$ Black $\color{Gray}\blacksquare$ Gray $\color{White}\blacksquare$ White $\color{DarkGray}\blacksquare$ DarkGray $\color{LightGray}\blacksquare$ LightGray $\color{Brown}\blacksquare$ Brown $\color{Lime}\blacksquare$ Lime $\color{Olive}\blacksquare$ Olive $\color{Orange}\blacksquare$ Orange $\color{Pink}\blacksquare$ Pink $\color{Purple}\blacksquare$ Purple $\color{Teal}\blacksquare$ Teal $\color{Violet}\blacksquare$ Violet 扩展颜色(68种) $\color{Apricot}\blacksquare$ Apricot $\color{Aquamarine}\blacksquare$ Aquamarine $\color{Bittersweet}\blacksquare$ Bittersweet $\color{Black}\blacksquare$ Black $\color{Blue}\blacksquare$ Blue $\color{BlueGreen}\blacksquare$ BlueGreen $\color{BlueViolet}\blacksquare$ BlueViolet $\color{BrickRed}\blacksquare$ BrickRed $\color{Brown}\blacksquare$ Brown $\color{BurntOrange}\blacksquare$ BurntOrange $\color{CadetBlue}\blacksquare$ CadetBlue $\color{CarnationPink}\blacksquare$ CarnationPink $\color{Cerulean}\blacksquare$ Cerulean $\color{CornflowerBlue}\blacksquare$ CornflowerBlue $\color{Cyan}\blacksquare$ Cyan $\color{Dandelion}\blacksquare$ Dandelion $\color{DarkOrchid}\blacksquare$ DarkOrchid $\color{Emerald}\blacksquare$ Emerald $\color{ForestGreen}\blacksquare$ ForestGreen $\color{Fuchsia}\blacksquare$ Fuchsia $\color{Goldenrod}\blacksquare$ Goldenrod $\color{Gray}\blacksquare$ Gray $\color{Green}\blacksquare$ Green $\color{GreenYellow}\blacksquare$ GreenYellow $\color{JungleGreen}\blacksquare$ JungleGreen $\color{Lavender}\blacksquare$ Lavender $\color{LimeGreen}\blacksquare$ LimeGreen $\color{Magenta}\blacksquare$ Magenta $\color{Mahogany}\blacksquare$ Mahogany $\color{Maroon}\blacksquare$ Maroon $\color{Melon}\blacksquare$ Melon $\color{MidnightBlue}\blacksquare$ MidnightBlue $\color{Mulberry}\blacksquare$ Mulberry $\color{NavyBlue}\blacksquare$ NavyBlue $\color{OliveGreen}\blacksquare$ OliveGreen $\color{Orange}\blacksquare$ Orange $\color{OrangeRed}\blacksquare$ OrangeRed $\color{Orchid}\blacksquare$ Orchid $\color{Peach}\blacksquare$ Peach $\color{Periwinkle}\blacksquare$ Periwinkle $\color{PineGreen}\blacksquare$ PineGreen $\color{Plum}\blacksquare$ Plum $\color{ProcessBlue}\blacksquare$ ProcessBlue $\color{Purple}\blacksquare$ Purple $\color{RawSienna}\blacksquare$ RawSienna $\color{Red}\blacksquare$ Red $\color{RedOrange}\blacksquare$ RedOrange $\color{RedViolet}\blacksquare$ RedViolet $\color{Rhodamine}\blacksquare$ Rhodamine $\color{RoyalBlue}\blacksquare$ RoyalBlue $\color{RoyalPurple}\blacksquare$ RoyalPurple $\color{RubineRed}\blacksquare$ RubineRed $\color{Salmon}\blacksquare$ Salmon $\color{SeaGreen}\blacksquare$ SeaGreen $\color{Sepia}\blacksquare$ Sepia $\color{SkyBlue}\blacksquare$ SkyBlue $\color{SpringGreen}\blacksquare$ SpringGreen $\color{Tan}\blacksquare$ Tan $\color{TealBlue}\blacksquare$ TealBlue $\color{Thistle}\blacksquare$ Thistle $\color{Turquoise}\blacksquare$ Turquoise $\color{Violet}\blacksquare$ Violet $\color{VioletRed}\blacksquare$ VioletRed $\color{White}\blacksquare$ White $\color{WildStrawberry}\blacksquare$ WildStrawberry $\color{Yellow}\blacksquare$ Yellow $\color{YellowGreen}\blacksquare$ YellowGreen $\color{YellowOrange}\blacksquare$ YellowOrange Reference Using_colours_in_LaTeX</content></entry><entry><title>Iperf3</title><url>/posts/202212/iperf3/</url><categories><category><no value=/></categories><tags><tag>iperf3</tag><tag>performance</tag></tags><content type="html"><![CDATA[installation sudo apt install iperf3 -y test tcp speed/throughput start server on serverA(server mode) iperf3 -s -p [default port 5201] start server on serverB(client mode) iperf3 -c &lt;ip of serverA&gt; -p [serverA port] test udp speed/throughput start server on serverA(server mode) same with tcp
iperf3 -s -p [default port 5201] use -u option on client side
start server on serverB(client mode) iperf3 -c &lt;ip of serverA&gt; -u -p [serverA port] more client options number of parallel client threads Pass the -P option
set time in seconds to transmit for (default 10 secs) Pass the -t option
examples run on serverA
iperf3 -s run on serverB
iperf3 -c x -P 3 -t 30 ]]></content></entry><entry><title>Linux Compression Tool</title><url>/posts/202212/linux-compression-tool/</url><categories><category>blog</category></categories><tags><tag>linux</tag><tag>compression</tag><tag>tool</tag></tags><content type="html"><![CDATA[ubuntu 22.04默认安装 pigz pigz : 是gzip的并行实现，是gzip的全功能替代品，它在压缩数据时充分利用多个处理器和多个内核。
tar with pigz
# uncompress tar -I pigz -xf &lt;filename.tar.gz&gt; # compress tar -I pigz -cf &lt;filename.tar.gz&gt; &lt;dir or file&gt; # compress with options tar cf - &lt;paths-to-archive&gt; | pigz -9 -p 32 &gt; &lt;archive.tar.gz&gt; Zstandard Zstandard : Zstandard是一种快速压缩算法，可提供高压缩比。它还为小数据提供了一种特殊模式，称为字典压缩。 参考库提供了非常广泛的速度/压缩权衡，并由极快的解码器支持）。Zstandard库作为开源软件使用BSD许可证提供。其格式稳定并作为IETF RFC 8878发布。
Gzip Gzip : 是一种单文件/流无损数据压缩实用程序，其中生成的压缩文件通常具有后缀 .gz。 gzip还指该实用程序使用的相关压缩数据格式。
bzip2 bzip2 : 是免费提供的、无专利（见下文）的高质量数据压缩器。它通常将文件压缩到最佳可用技术（PPM统计压缩器系列）的10%到15%以内，同时压缩速度大约是其两倍，解压缩速度大约是其六倍。
p7zip p7zip : 用于Unix的7z.exe和7za.exe（7zip的命令行版本，请参阅www.7-zip.org）的快速移植。 7-Zip 是具有最高压缩比的文件归档器。
XZ Utils XZ Utils : 是一款免费的通用数据压缩软件，具有高压缩比。XZ Utils是为类POSIX系统编写的，但也适用于一些不太POSIX的系统。 XZ Utils是LZMA Utils的继承者。
ubuntu 22.04未默认安装 LZ4 lz4 : 是无损压缩算法，提供每核&gt;500MB/s的压缩速度，可通过多核CPU进行扩展。它具有极快的解码器，每个内核的速度可达数GB/s，通常在多核系统上达到RAM速度限制。
lzop lzop : 是一种强大的压缩工具，它使用Lempel-Ziv-Oberhumer(LZO)压缩算法。它通过交易压缩比提供极快的压缩速度。 例如，与gzip相比，它生成的文件稍大，但只需要10%的CPU运行时间。此外，lzop可以通过多种方式处理系统备份，包括备份模式、单文件模式、存档模式和管道模式。
pixz pixz : 是XZ压缩器的并行实现，支持数据索引。它不是生成像xz这样的一大块压缩数据，而是创建一组较小的块。 这使得随机访问原始数据变得简单明了。此外，pixz还确保文件权限在压缩和解压缩期间保持原样。
plzip plzip : 是一种无损数据压缩工具，它创造性地利用了现代CPU支持的多线程功能。它建立在lzlib库之上，提供类似于gzip和bzip2的命令行界面。 plzip的一个主要优点是它能够充分利用多处理器机器。对于需要高性能Linux压缩工具来支持并行压缩的管理员来说，plzip绝对值得一试。
Reference 10 Best Compression Tools for Linux ]]></content></entry><entry><title>LVM</title><url>/posts/202212/lvm/</url><categories><category><no value=/></categories><tags><tag>lvm</tag></tags><content type="html">介绍 Physical Volumes (PV): 物理卷, 对应实际的物理磁盘 (如： /dev/sda, /dev,sdb 等) Volume Groups (VG)： 卷组, 由物理卷组成（如： vg=/dev/sda + /dev/sdb） Logical Volumes (LV): 逻辑卷, 由卷组划分而来 显示信息 显示物理卷信息 键入以下命令以查看有关物理卷的信息
sudo pvs 要查看详细的物理卷属性信息
sudo pvdisplay 显示卷组信息 键入以下命令以查看有关卷组的信息
sudo vgs 要查看详细的卷组属性信息
sudo vgdisplay 显示逻辑卷信息 键入以下命令以查看有关逻辑卷的信息
sudo lvs 要查看详细的逻辑卷属性信息
sudo lvdisplay 查找磁盘信息 # list all disk sudo fdisk -l # list all disk with grep sudo fdisk -l | grep &amp;#39;^Disk /dev/&amp;#39; 扩展LVM 创建新的PV sudo pvcreate /dev/sdb # or [-f] 强制创建PV。[-ff] 强制创建PV，并覆盖现有磁盘(忽略磁盘检查) sudo pvcreate -ff /dev/sdc 如果执行上述命令出现device is partitioned，那么进行下面检查:
sudo fdisk -l /dev/sdb 如果出现类似Disklabel type: gpt的字样那么需要进行额外的操作。(当您拥有GPT（GUID 分区表）时可能会发生这种情况。不幸的是，这甚至不能用 -f 强制执行)
sudo wipefs --all --backup /dev/sdb 执行上述命令后，直接执行sudo pvcreate /dev/sdb，提示成功
将新的pv添加到vg中 sudo vgextend vgubuntu /dev/sdb 扩展对应的lv sudo lvm lvextend -l +100%FREE /dev/vgubuntu/root 扩展对应的分区 df -h sudo resize2fs -p /dev/mapper/vgubuntu-root df -h</content></entry><entry><title>Useful linux commands</title><url>/posts/202212/useful-linux-commands/</url><categories><category>blog</category></categories><tags><tag>linux</tag></tags><content type="html"><![CDATA[create sudo enabled user # add a new user to the system sudo adduser &lt;username&gt; # adding the user to the sudo group sudo usermod -aG sudo &lt;username&gt; # testing sudo access sudo su - &lt;username&gt; run sudo command without a password sudo visudo # change under line to next line # %sudo ALL=(ALL:ALL) ALL %sudo ALL=(ALL:ALL) NOPASSWD:ALL install miniconda wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh bash Miniconda3-py38_4.12.0-Linux-x86_64.sh init miniconda # cd to conda install path ./bin ./conda init zsh # restart terminator conda create --name &lt;env_name&gt; --clone base nano ~/.zshrc # add under line in the bottom of ~/.zshrc conda activate &lt;env_name&gt; ]]></content></entry><entry><title>Docker Swarm</title><url>/posts/202211/docker-swarm/</url><categories><category>blog</category></categories><tags><tag>docker</tag><tag>swarm</tag></tags><content type="html"><![CDATA[Swarm 与Docker Engine集成的集群管理: 创建一组Docker引擎，可以在其中部署应用程序服务。不需要额外的编排软件来创建或管理swarm。 分散式设计: Docker引擎不是在部署时处理节点角色之间的差异，而是在运行时处理特殊化。Docker引擎支持两种类型的节点：managers和workers。这意味着您可以从单个磁盘映像构建整个群。 声明式服务模型： Docker引擎使用声明式方法让您定义应用程序堆栈中各种服务的所需状态。例如：描述一个应用程序，该应用程序由具有消息队列服务的Web前端服务和数据库后端组成。 缩放：对于每个服务，可以声明要运行的任务数。当放大或缩小服务时，群管理器会通过添加或删除任务来自动适应以维持所需的状态。 期望的状态和重新调整：swarm管理器节点持续监控集群状态并协调实际状态与您表达的期望状态之间的任何差异。例如，如果设置一个服务运行10个容器副本，而其中两个副本的工作机器崩溃，则管理器创建两个新副本来替换崩溃的副本。集群管理器将新副本分配给正在运行且可用的workers上。 多主机网络：可以为您的服务指定覆盖网络(overlay network)。集群管理器在初始化或更新应用程序时自动为覆盖网络上的容器分配地址。 服务发现: Swarm管理器节点为swarm中的每个服务分配一个唯一的DNS名称并负载平衡运行的容器。您可以通过嵌入在swarm中的DNS服务器查询在swarm中运行的每个容器。 负载均衡: 您可以将服务端口公开给外部负载均衡器。在内部，swarm允许您指定如何在节点之间分发服务容器。 默认安全: 集群中的每个节点都强制执行TLS相互身份验证和加密，以确保自身与所有其他节点之间的通信安全。您可以选择使用自签名根证书或来自自定义根CA的证书。 滚动更新: 在滚动更新时，您可以逐步将服务更新应用于节点。集群管理器允许您控制服务部署到不同节点集之间的延迟。如果出现任何问题，您可以回滚到以前版本的服务。 Init 初始化一个群。此命令的目标 docker 引擎成为新创建的单节点群中的管理器。
docker swarm init --advertise-addr 192.168.1.123 Join 将节点加入群。该节点根据您使用&ndash;token标志传递的令牌作为管理节点或工作节点加入。如果您传递一个manager令牌，该节点将作为manager加入。如果您传递worker令牌，则该节点将作为worker加入。
docker swarm join --token xxx 192.168.1.123:2377 下面命令需在manager节点执行获取对应的token
# 获取加入workers的token docker swarm join-token worker # 获取加入managers的token docker swarm join-token manager 节点管理 ls 在manager节点执行下面命令，查看所有节点列表
docker node ls Promote 将一个或多个节点提升为集群中的管理器
docker node promote &lt;node-id&gt; Demote 从群中的管理器中降级一个或多个节点
docker node demote &lt;node-id&gt; Get All Labels as map # run command under swarm manager docker node ls -q | xargs docker node inspect -f &#39;{{ .ID }} [{{ .Description.Hostname }}]: {{ .Spec.Labels }}&#39; Get All Labels # run command under swarm manager docker node ls -q | xargs docker node inspect \ -f &#39;{{ .ID }} [{{ .Description.Hostname }}]: {{ range $k, $v := .Spec.Labels }}{{ $k }}={{ $v }} {{end}}&#39; Backup Labels docker node ls -q | xargs docker node inspect \ -f &#39;docker node update {{ range $k, $v := .Spec.Labels }}--label-add {{ $k }}={{ $v }} {{end}}{{ .Description.Hostname }}&#39; Add Labels Run docker node update &ndash;label-add on a manager node to add label metadata to a node. The &ndash;label-add flag supports either a or a = pair.
当只输入时，得到的是一个空值标签 再次使用update可以更新该值标签 docker node update --label-add &lt;key&gt; --label-add &lt;key&gt;=&lt;value&gt; &lt;node_hostname&gt; Remove Labels docker node update --label-rm &lt;key&gt; &lt;node_hostname&gt; ]]></content></entry><entry><title>Many Factors Affecting Optimization</title><url>/posts/202211/05-many-factors-affecting-optimization/</url><categories><category><no value=/></categories><tags><tag>optimization</tag></tags><content type="html"><![CDATA[机器学习的一般步骤 Model Bias The model is too simple. find a needle in a haystack (大海捞针) but there is no needle Solution: redesign your model to make it more flexible more features more neurons, layers Optimization Issue Large loss not always imply model bias. There is another possibility &hellip; A needle is in a haystack&hellip;, Just cannot find it. Model Bias v.s. Optimization Issue Gaining the insights from comparison 当在测试数据上和训练数据上有着类似的loss曲线时，这说明是Optimization Issue的问题 Optimization Issue Start from shallower networks(or other models), which are easier to optimize. 从更容易优化的较浅的网络（或其他模型）开始。 If deeper networks do not obtain smaller loss on training data, then there is optimization issue. 如果更深的网络在“训练数据”上没有获得更小的损失，那么就存在优化问题。 Overfitting Small loss on training data, large loss on testing data. Why? 数据分布的这条虚线通常是无法明确的获知的，我们通常只能拿到在这条曲线上的多个Training Data 由于model的Flexible, 训练出来的这个模型，在没有训练数据的地方会有“freestyle”, 从而导致测试数据的overfitting 增加训练数据 Data augmentation(用一些对这个问题的理解，自己创造出新的训练数据。例如：对图片左右反转，或者是截取其中一块等) 通过限制model来解决overfitting，给model制造限制的方法： make your model simpler Less parameters, sharing parameters Fully-connected的架构是一个比较有弹性的架构；而CNN是一个比较有限制的架构（根据影像的特性来限制模型的弹性） Less features Early stopping Regularization Dropout 这里需要注意，太多的限制和太简单的模型会导致model bias Bias-Complexity Trade-off 通过观察Training loss和Testing loss的loss曲线来选择model和对应的模型限制 N-fold Cross Validation Cross Validation就是N-flod Cross Validation的一个特例 如果使用Cross Validation, 则使用Validation Set的loss最小进行模型的选择 当使用N-fold Cross Validation时，则使用mse的avg最小来挑选模型 Mismatch Your training and testing data have different distributions. 需要对训练资料和测试资料有一定的了解才能分清到底是不是mismatch mismatch和overfitting不是一个东西，overfitting可以通过增加训练资料来解决，而mismatch无法通过增加训练资料来解决 Optimization Fails because loss is Not small enough, because the gradient is close to zero. Gradient为零的情况有：local minima, local maxima, saddle point等 saddle point: Gradient为零, 同时既不是local minima也不是local maxima的地方 Gradient为零的点统称为critical point Tayler Series Approximation(泰勒级数逼近) 如何知道一个critical point是local minima还是saddle point 其中包括 Gradient $\color{green}g$ is a vector, Hessian $\color{red}H$ is a matrix. Hessian Gradient $\color{green}g$ 为0时，则可知目前所在位置为临界点Critical Point Hessian $\color{red}H$ can telling the properties of critical points. 当$\color{red}H$这个矩阵中的值全部为正值，则当前所在为Local Minima 当$\color{red}H$这个矩阵中的值全部为负值，则当前所在为Local Maxima 当$\color{red}H$这个矩阵中的值有正有负，则当前所在为Saddle Point Saddle Point v.s. Local Minima 在一维的空间中看到的local minima，在二维的空间中看到的可能就只是saddle point. 当我们有更多的参数，也许local minima是很少见的 Minimum Ratio 是所有Local Minima的数量与所有Critical Point的比值 从图上可知，最大的ratio也只是0.6 图上Eigen Values就是前文所说的Hessian Matrix. Batch 不会拿所有的资料去算微分，会把所有的资料分成很多个batch， 每个batch的资料算一个loss，算一个Gradient再update参数 所有的资料算过一遍叫做一个epoch shaffle after each epoch, shaffle有很多不同的做法： 一个常见的做法是在每个epoch开始之前，会分一次batch，每一个epoch的batch都不一样 Small Batch v.s. Large Batch Consider we have 20 examples(N=20) Batch size = N (Full batch) Update after seeing all the 20 examples Long time for cooldown but powerful Batch size = 1 Update for each example, Update 20 times in an epoch Short time for cooldown but noisy 由于有GPU的平行运算的能力，从性能的角度出发得到如下结论： Larger batch size does not require longer time to compute gradient(unless batch size is too large) Smaller batch requires longer time for one epoch (longer time for seeing all data once) 从准确率来看 反而是有noisy的batch可以得到好的结果。Smaller batch size has better performance. 如下图，横轴是batch size，纵轴是正确率。如图可知batch size越大，validation set上的结果越差。 这个是overfitting么？这个不是overfitting, 因为我们用的数据和模型都是一致的。所以这里发生在larger batch size上的情况是Optimization Fails. 为什么在Noisy的batch size上update更好呢？一种可能的解释是：
Full Batch比较容易stuck，而Small Batch由于不同batch的数据有所不同，所以相对来说不太容易stuck，更容易train到比较小的loss 有研究表明，小的batch size不仅针对training有效，在testing的时候也比大的batch size要好。如下图：
数据相同，模型相同的情况下，将大的batch size在training set上的accuracy调整的和小的batch size一样 而从图上右侧表格观察，LB的accuracy比SB的accuracy要差，这是overfitting 详见资料： On Large-Batch Training for deep Learning: Generalization Gap and Sharp Minima 为什么会有这种现象呢？
假设如下图的training loss上有很多个Local Minima，这些Local Minima的Loss都足够小 但是Local Minima还是有好坏之分的。如图中，Flat minima（盆地）的容错性要优于sharp minima（峡谷）。 大的batch size倾向于走到峡谷里面，而小的batch size倾向于走到盆地里面。 小的batch size有很多的noisy，它每次走的方向都不太一样，如果这个峡谷比较的窄，那么noisy的batch size很容易跳出峡谷。 Small Large Speed for one update (no parallel) Faster Slower speed for one update (with parallel) Same Same(not too large) Time for one epoch Slower Faster Gradient Noisy Stable Optimization Better Worse Generalization Better Worse Batch size is a hyperparameter you have to decide. 兼顾速度与Generalization的研究文章 Large Batch Optimization for Deep Learning: Training BERT in 76 minutes Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes Stochastic Weight Averaging in Parallel: Large-Batch Training that Generalizes Well Large Batch Training of Convolutional Networks Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour Momentum (Vanilla) Gradient Descent Gradient Descent + Momentum Movement: movement of last step minus gradient at present Adaptive Learning Rate $ \text{Training stuck} \ne \text{Small Gradient} $ 当loss不再下降的时候，需要确认一下Gradient是否为0；即loss不再下降需要分析stuck的原因 如图，当loss不再下降时，norm of gradient 并没有为0 Training can be difficult even without critical points.
Learning rate cannot be one-size-fits-all(一刀切). Different parameters needs different learning rate. 相对平坦的Gradient Descent需要较大的Learning Rate 相对尖锐的Gradient Descent需要较小的Learning Rate Formulation for one parameter:
\begin{align} \theta_i^{t+1} &amp; \leftarrow \theta_i^t - {\color{red}\eta}g_i^t \cr g_i^t &amp; = \frac{\partial L}{\partial \theta_i} |_{\theta=\theta^t} \cr &amp; \Downarrow \cr \theta_i^{t+1} &amp; \leftarrow \theta_i^t - {\color{red}\frac{\eta}{\sigma_i^t}}g_i^t \end{align}
${\color{red}\frac{\eta}{\sigma_i^t}}$就是Parameter dependent的Learning Rate,下面介绍几种常见的计算方法：
Root Mean Square (Used in Adagrad) \begin{align} \theta_i^1 &amp; \leftarrow \theta_i^0 - \frac{\eta}{\sigma_i^0}g_i^0 &amp; \sigma_i^0 &amp;= \sqrt{(g_i^0)^2} = |g_i^0| \cr \theta_i^2 &amp; \leftarrow \theta_i^1 - \frac{\eta}{\sigma_i^1}g_i^1 &amp; \sigma_i^1 &amp;= \sqrt{\frac{1}{2}[(g_i^0)^2+(g_i^1)^2]} \cr \theta_i^3 &amp; \leftarrow \theta_i^2 - \frac{\eta}{\sigma_i^2}g_i^2 &amp; \sigma_i^2 &amp;= \sqrt{\frac{1}{3}[(g_i^0)^2+(g_i^1)^2+(g_i^2)^2]} \cr &amp; \vdots \cr \theta_i^{t+1} &amp; \leftarrow \theta_i^t - \frac{\eta}{\sigma_i^t}g_i^t &amp; \sigma_i^t &amp;= \sqrt{\frac{1}{t+1}\sum_{i=0}^t(g_i^t)^2} \end{align}
小的$\sigma_i^t$会有大的step 大的$\sigma_i^t$会有小的step Learning rate adapts dynamically 即使针对同一个参数，在不同的时候，可能也需要有不同的Learning Rate RMSProp \begin{align} \theta_i^1 &amp; \leftarrow \theta_i^0 - \frac{\eta}{\sigma_i^0}g_i^0 &amp; \sigma_i^0 &amp;= \sqrt{(g_i^0)^2} = |g_i^0| \cr &amp; &amp; &amp; \text{设 } 0 &lt; \alpha &lt; 1 \cr \theta_i^2 &amp; \leftarrow \theta_i^1 - \frac{\eta}{\sigma_i^1}g_i^1 &amp; \sigma_i^1 &amp;= \sqrt{\alpha(\sigma_i^0)^2 + (1-\alpha)(g_i^1)^2} \cr \theta_i^3 &amp; \leftarrow \theta_i^2 - \frac{\eta}{\sigma_i^2}g_i^2 &amp; \sigma_i^2 &amp;= \sqrt{\alpha(\sigma_i^1)^2 + (1-\alpha)(g_i^2)^2]} \cr &amp; \vdots \cr \theta_i^{t+1} &amp; \leftarrow \theta_i^t - \frac{\eta}{\sigma_i^t}g_i^t &amp; \sigma_i^t &amp;= \sqrt{\alpha(\sigma_i^{t-1})^2 + (1-\alpha)(g_i^t)^2} \end{align}
Adam: RMSProp + Momentum Learning Rate Scheduling Learning Rate Decay After the training goes, we are closer to the destination, so we reduce the learning rate. Warm Up Increase and then decrease? Deep Residual Learning for Image Recognition Attention Is All You Need On the Variance of the Adaptive Learning Rate and Beyond Summary Of Optimization Momentum: weighted sum of the previous gradients (考虑方向) $\sigma_i^t$: 只考虑大小不考虑方向 $\eta^t$: Learning rate scheduling Loss for Classification Class as one-hot vector one-hot vector for multi-output Soft-max soft-max对上层多输出结果做一个normalize 并且让大的值和小的值之间的差距更大 soft-max有时又叫做logit Loss function Mean Square Error (MSE): $ e = \sum\limits_i(\hat y_i - y_i^\prime)^2 $ Cross-entropy: $ e = -\sum\limits_i \hat y_i ln y_i^\prime $ Minimizing cross-entropy is equivalent to maximizing likelihood. Loss function affect Optimization 设目前做一个三分类的模型，当前这个分类的结果是$ \hat y = \begin{bmatrix}1 \cr 0 \cr 0 \end{bmatrix} $ e表示$y到\hat y$之间的距离，可以是MSE，也可以是Cross-entropy $y_1$的取值范围为[-10, 10], $y_2$的取值范围为[-10, 10], $y_3$的取值为固定值-1000 下图左右分别为MSE和Cross-entropy想对于y的取值的Error Surface, 这两张图中Error Surface的特点都是右下角loss小，左上角loss大 假设我们开始的地方都是左上角：如果我们选择Cross-entropy，左上角的地方是有斜率的,所以可以通过gradient的方法一路向右下角走达到small loss; 如果我们选择MSE，我们就卡住了，在MSE左上角这个loss很大的地方，它的gradient非常小，趋进于零，而距离目标又很远，没有很好的办法通过gradient的方法走到右下角。 所以如果做classification时，选择使用MSE做loss时，有很大可能性train不起来; 当然如果使用类似Adam这些好的Optimizer时，也许有机会走到右下角。 Changing the loss function can change the difficulty of optimization. Normalization Changing Landscape $w_1, w_2$与不同的feature相关，由于不同的feature范围不同，导致了$w_1, w_2$的变动对最终的loss产生不同的影响 是否可以找到一个方法，让不同的feature有着相似的range Feature Normalization 下图只是Feature Normalization的一种可能 $ x^1, x^2, \cdots, x^R $ 为数据的R个features For each dimension i: $m_i$ : mean $\sigma_i$ : standard deviation Normalization: $\tilde{x}_i^r \leftarrow \frac{x_i^r-m_i}{\sigma_i} $ The means of all dims are 0, and the variances are all 1 In general, feature normalization makes gradient descent converge faster. $\theta$的Normalization $\tilde{x}^1$在经过$W^1$后得到的$z^1$也是具有不同的range的，这将导致针对$W^2$的optimize会比较的困难 对于$W^2$来说，这里的z或者a也是feature，所以这里需要考虑对z或者a做Normalization 那么到底在激活函数的前面还是后面做normalization呢？实作中都可以，但当activation function为Sigmoid时，建议在Sigmoid的前面，也就是这里的z做normalization。 Feature Normalization的计算 $\mu = \frac{1}{n}\sum\limits_{i=1}^nz^i $ $ \sigma = \sqrt{\frac{1}{n}\sum\limits_{i=1}^n(z^i-\mu)^2} $ $ \tilde{z}^i = \frac{z^i-\mu}{\sigma} $ Batch normalization 由于需要对$x, z^1, z^2, \cdots, z^n$都做normalization，所以这是一个巨大的network，如果使用这个巨大的network针对所有的数据去求$\mu和\sigma$是不太现实的， 所以只能将范围缩小到一个batch，从而诞生了batch normalization。 而在做Batch normalization的时候，往往还会加上一个$\beta和\gamma$， 得到方程$ \hat{z}^i = \gamma\odot\tilde{z}^i+\beta $ 其中 $ \tilde{z}^i = \frac{z^i-\mu}{\sigma} $ 实际在做训练时，考虑到normalization的情况，在初始情况下$\gamma$会被初始化为one vector(全1的向量), 而$\beta$会被初始化为zero vector(全0的向量)。 Batch normalization - Testing We do not always have batch at testing stage. Computing the moving average of $\mu$ and $\sigma$ of the batches during training. 如下计算出$\bar{\mu}, \bar{\sigma}$，替换training中的表达式$ \tilde{z} = \frac{z-\mu}{\sigma} $得到$ \tilde{z} = \frac{z-\bar{\mu}}{\bar{\sigma}} $ How to compute moving average? \begin{align} \mu^1, \mu^2, \mu^3, \cdots, \mu^t \cr \bar{\mu} \leftarrow p\bar{\mu} + (1-p)\mu^t \end{align}
Batch Normalization Refs Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift How Does Batch Normalization Help Optimization Experimental results (and theoretically analysis) support batch normalization change the landscape of error surface. This suggests that the positive impact of BatchNorm on training might be somewhat serendipitous(偶然的，发现了一个意料之外的东西). Normalization Refs Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models Layer Normalization Instance Normalization: The Missing Ingredient for Fast Stylization Group Normalization Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks Spectral Norm Regularization for Improving the Generalizability of Deep Learning New Optimization What you have known before? SGD - stochastic gradient descent: 随机梯度下降 SGDM - stochastic gradient descent with momentum Adagrad RMSProp Adam Some Notations $\theta_t$: model parameters at time step t $\nabla L(\theta_t) \text{or } g_t$: gradient at $\theta_t$, used to compute $\theta_{t+1}$ $m_{t+1}$: momentum accumulated from time step 0 to time step t, which is used to compute $\theta_{t+1}$ \begin{align} g_t \cr \overleftarrow{x_t \rightarrow \theta_t \rightarrow y_t ^\underleftrightarrow{L(\theta_t;x_t)} \hat{y}_t} \end{align}
What is Optimization about ? Find a $\theta$ to get the lowest $\sum_x L(\theta; x)$ !! Or, Find a $\theta$ to get the lowest $L(\theta)$ !! On-line vs Off-line learning On-line: one pair of $(x_t, \hat{y}_t)$ at a time step Off-line: pour all $(x_t, \hat{y}_t)$ into the model at every time step SGD (stochastic gradient descent) Start at position $\theta^0$ Compute gradient at $\theta^0$ Move to $\theta^1 = \theta^0 - \eta \nabla L(\theta^0)$ Compute gradient at $\theta^1$ Move to $\theta^2 = \theta^1 - \eta \nabla L(\theta^1)$ Stop until $\nabla L(\theta^t) \approx 0$ SGDM (stochastic gradient descent with momentum) Start at point $\theta^0$ Movement $V^0=0$ Compute gradient at $\theta^0$ Movement $V^1=\lambda V^0 - \eta \nabla L(\theta^0)$ Move to $\theta^1 = \theta^0 + V^1$ Compute gradient at $\theta^1$ Movement $V^2 = \lambda V^1 - \eta \nabla L(\theta^1)$ Move to $\theta^2 = \theta^1 + V^2$ Adagrad $\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\sum_{i=0}^{t-1}(g_i)^2}}g_{t-1}$ RMSProp $\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{v_t}}g_{t-1}$ $v_1 = g_0^2$ $v_t = \alpha v_{t-1} + (1-\alpha)(g_{t-1})^2$ Adam $ \theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{v}_t} + \varepsilon}\hat{m}_t $ Optimizers: Real Application BERT: 作Q/A， 文章生成， 2018年提出，使用 ADAM Transformer: 用于翻译， 使用 ADAM Tacotron: 最早使用神经网络作逼真的语音生成的模型, 2017年提出, 使用 ADAM Yolo: 使用 SGDM Mask R-CNN: 使用 SGDM ResNet: 使用 SGDM Gig-GAN: 生成影像， 使用 ADAM MEMO: 在不同的分类任务中学到共同的资讯， 使用 ADAM Adam vs SGDM Adam: fast training, large generalization gap, unstable SGDM: stable, little generalization gap, better convergence(?) Simply combine Adam with SGDM? SWATS: Begin with Adam(fast), end with SGDM Towards improving Adam Troubleshooting 根据前面的计算公式，从100000到100998的梯度都是1,所以movement都是$\eta$ 第100999步的梯度很大，100000,对应的movement为$10\sqrt{10}\eta$ 这导致了前面很多无用的批次的梯度产生了约1000$\eta$的无用变化（乱走），而其中一个有用的很小的批次带来的变化只有33个$\eta$ 当梯度大部分都很小时，就会产生这样的问题；有用的大的梯度对应的批次会被大量的小的无用的梯度牵着鼻子走 AMSGrad Reduce the influence of non-informative gradients Remove de-biasing due to the max operation 这个算法的改进可以类比为Adagrad和RMSProp, 所以感觉并没有起到很好的效果 Troubleshooting In the final stage of training, most gradients are small and non-informative, while some mini-batches provide large informative gradient rarely Learning rates are either extremely large(for small gradients) or extremely small(for large gradients) AdaBound AMSGrad only handles large learning rates AdaBound的公式中，有参数并非adaptive的，而是有点工程方法 Towards Improving SGDM Adaptive learning rate algorithms: dynamically adjust learning rate over time SGD-type algorithms: fix learning rate for all updates&hellip; too slow for small learning rates and bad result for large learning rates There might be a &ldquo;best&rdquo; learning rate? Learning Rate range test Learning Rate 在很大或很小的时候，性能都不会很好 Learning Rate 适中的时候，性能才比较好 Cyclical LR learning rate: decide by LR range test step size: several epochs avoid local minimum by varying learning rate learning rate在大小，大小的循环进行变化 变大的时候时在作exploration(探索)，变小的时候是在作收敛 The more exploration the better! SGDR 不用象Cyclical LR一样不断的变大再变小，而是在变小后，重新变回初始值重新开始 One-Cycle LR warm-up + annealing + fine-tuning Does Adam need warm-up? distorted(扭曲的) gradient -&gt; distorted EMA squared gradients -&gt; Bad learning rate keep your step size small at the beginning of training helps to reduce the variance of the gradients 新的warm-up的方法是，先变小，再变大 RAdam RAdam vs SWATS RAdam SWATS Inspiration 灵感 Distortion of gradient at the beginning of training results in inaccurate adaptive learning rate 训练开始时梯度失真导致自适应学习率不准确 non-convergence and generalization gap of Adam, slow training of SGDM Adam 的不收敛和泛化差距，SGDM 训练缓慢 How Apply warm-up learning rate to reduce the influence of inaccurate adaptive learning rate 应用预热学习率减少自适应学习率不准确的影响 Combine their advantages by applying Adam first, then SGDM 通过先应用 Adam，然后应用 SGDM 来结合它们的优势 Switch SGDM to RAdam Adam to SGDM Why switch The approximation of the variance of $\hat{v}_t$ is invalid at the beginning of training 方差的近似值$\hat{v}_t$在训练开始时无效 To purse better convergence 追求更好的收敛 Switch point When the approximation becomes valid 当近似值成立时 Some human-defined criteria 一些人为定义的标准 K step forward, 1 step back Lookahead: universal wrapper for all optimizers 这个算法有两组weight： 这里$\theta$是用于explore(探索)的，叫做Fast weights $\phi$是真正需要的weight，叫做Slow weights 循环分外循环和内循环。 内循环会走k步，内循环的Optim可以使用任意的optimizer 每走完一遍内循环，根据当前位置，到内循环开始前的位置，根据$\alpha$计算出下次循环开始的位置 接下来，使用新计算出来的$\phi$进行新一轮的内循环 这个方法和Memo里面的演算法Reptile很像 \begin{align} &amp; \text{For }t = 1, 2, \dots \text{(outer loop)} \cr &amp; \theta_{t,0} = \phi_{t-1} \cr &amp; \text{For } i = 1, 2, \dots, k \text{(inner loop)} \cr &amp; \theta_{t,i} = \theta_{t, i-1} + \text{Optim(Loss, data, }\theta_{t, i-1}\text{)} \cr &amp; \phi_t = \phi_{t-1} + \alpha(\theta_{t,k} - \phi_{t-1}) \end{align}
1 step back: avoid too dangerous exploration, 避免走入一个峡谷的minima Look for a more flatten minimum, 寻找更多的平坦的minima More stable Better generalization More than momentum Can we look into the future? Nesterov accelerated gradient (NAG) SGDM $ \theta_t = \theta_{t-1} - m_t $ $ m_t = \lambda m_{t-1} + \eta \nabla L (\theta_{t-1}) $ Look into the future $ \theta_t = \theta_{t-1} - m_t $ $ m_t = \lambda m_{t-1} + \eta \nabla L (\theta_{t-1} - \lambda m_{t-1}) $ \begin{align} \text{Let } {\theta_t}^\prime &amp;= \theta_t - \lambda m_t \cr &amp;= \theta_{t-1} - m_t - \lambda m_t \cr &amp;= \theta_{t-1} - \lambda m_t - \lambda m_{t-1} - \eta \nabla L(\theta_{t-1} - \lambda m_{t-1}) \cr &amp;= {\theta_{t-1}}^\prime - \lambda m_t - \eta \nabla L({\theta_{t-1}}^\prime) \cr m_t &amp;= \lambda m_{t-1} + \eta \nabla L({\theta_{t-1}}^\prime) \end{align}
Adam in the future Nadam $ \theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{v}}+\varepsilon} \hat{m}_t $ $ \hat m_t = \frac{\beta_1 m_t}{1-{\beta_1}^{t+1}} + \frac{(1-\beta_1) g_{t-1}}{1-{\beta_1}^t} $ SGDM $ \hat m_t = \frac{1}{1-{\beta_1}^t}(\beta_1 m_{t-1} + (1-\beta_1)g_{t-1}) $ $ = \frac{\beta_1m_{t-1}}{1-{\beta_1}^t} + \frac{(1-\beta_1)g_{t-1}}{1-{\beta_1}^t} $ Do you really know your optimizer? A story of L2 regularization AdamW &amp; SGDW with momentum SGDWM AdamW Something helps optimization 增加随机性的方法 Shuffling Dropout： 增加随机性的方法 Gradient noise: 在计算Gradient后，加上一个高斯的noise The more exploration, the better 和Learning Rate调整相关的方法 Warm-up Curriculum learning: 比如使用没有噪音的声音去训练它，等到它足够强的时候，再融入有噪音的训练样本。 Train your model with easy data(e.g. clean voice) first, then difficult data. Perhaps helps to improve generalization. Fine-tuning Teach your model patiently! Normalization Batch Normalization Instance Normalization Group Normalization Layer Normalization Positional Normalization Regularization Optimize method Team SGD SGD SGDM Learning rate scheduling NAG SGDWM Team Adam Adagrad RMSProp Adam AMSGrad AdaBound Learning rate scheduling Radam Nadam AdamW SWATS Lookahead SGDM Adam Slow Fast Better convergence Possibly non-convergence Stable Unstable Smaller generalization gap Larger generalization gap SGDM Computer vision image classification segmentation object detection Adam NLP QA machine translation summary Speech synthesis GAN Reinforcement learning Reference Video ]]></content></entry><entry><title>Logistic Regression</title><url>/posts/202211/04-logistic-regression/</url><categories><category><no value=/></categories><tags><tag>logistic</tag><tag>regression</tag></tags><content type="html">Function Set We want to find $P_{w,b}(C_1|x)$ $P_{w, b}(C_1|x) = \sigma(z)$ $ z = w \cdot x + b = \sum\limits_iw_ix_i + b $ function set: $f_{w, b}(x) = P_{w, b}(C_1|x)$ // including all different w and b Goodness of a Function 取minima的 对象写成一个function，这个function是Cross entropy between two Bernoulli distribution Cross Entropy: $H(p, q) = - \sum\limits_xp(x)ln(q(x))$ cross entropy指的是p和q有多接近。如果p和q是一样的，则cross entropy等于0。 Cross Entropy Logistic Regression vs Linear Regression 在function set上: Logistic比Linear在function上多一个sigmoid函数 在loss上，Logistic是所有$f(x^n)和\hat y^n的$cross entropy的总和 在作Gradient Disent时，function是一样的 Logistic Regression vs Linear Regression 为什么Logistic Regression不能用Square Error作loss 参数的变化对Total Loss作图的话，黑色的是Cross Entropy, 红色的是Square Error，如图 Cross Entropy在距离中心最佳点解越远时微分值越大，越近时越小 而Square Error无论距离中心最佳点远或者近，微分值都相对比较小。这样导致距离目标远时，参数update的很慢。 Discriminative v.s. Generative 他们的function set是一样的: $ P(C_1|x) = \sigma(w \cdot x +b) $ 通常Discriminative的性能是强于Generative的，其原因主要是Generative的model是基于一些假设得到的。 不是所有情况下Discriminative的model都是强于Generative的 Benefit of generative model With the assumption of probability distribution, less training data is needed Discriminative的变化量受到data的变化量很大，随着数据越多，loss越小 With the assumption of probability distribution, more robust to the noise 假设data中有一些noise，则Generative要强于Discriminative Priors and class-dependent probabilities can be estimated from different sources. 语音辨识中，Model是Generative的。 Multi-class Classification [Bishop, P209-210] softmax会强化大的值 从高斯分布推导后，可以得到这个softmax 使用softmax作为输出得到$y$，最好的target $\hat y$，则当target是one hot vector时，$y和\hat y$的 Cross Entropy的值最小 Softmax Limitation of Logistic Regression 如下图情况，无法找到一个函数将Class1和Class2很好的区分开 可以通过Feature Transformation的方式对feature作转换，然后对转换后的值进行分类 Feature Transformation 假设通过某种方式将$x_1, x_2$转化为$x_1^\prime, x_2^\prime$，如图右边，则可以找到一个函数，将class1和class2区分开来 那么如何让机器自己找到这种函数呢？ Cascading logistic regression models 如下图，前面的Logistic是Feature Transformation，后面的Logistic是Classification reference video</content></entry><entry><title>Using Ghostscript</title><url>/posts/202211/ghostscript/</url><categories><category><no value=/></categories><tags><tag>ghostscript</tag><tag>pdf</tag></tags><content type="html">Ghostscript介绍 Ghostscript 是 PostScript®和可移植文档格式(PDF)文件的解释器。
Ghostscript 由 PostScript解释器层和图形库组成。图形库与Ghostscript系列中的所有其他产品共享，因此所有这些技术有时都称为 Ghostscript，而不是更正确的 GhostPDL。
GhostPDF: GhostPDF是PDF页面描述语言的解释器。 GhostPDL: 我们使用 GhostPDL 作为一个总称来涵盖我们的整个产品线。现在，我们将所有这些不同的产品整合到一个包中，恰当地称为 GhostPDL。除了我们现有的 PDL 模块（PS、PDF、PCL、PXL 和 XPS）之外，我们现在还添加了新模块来处理一系列常见的图像格式。安装这些后，GhostPDL 将处理 JPEG（JFIF 和 EXIF）、PWG、TIFF、PNG、JBIG2 和 JPEG2000。 GhostPCL: GhostPCL是PCL™和PXL文件的解释器。这包括一个连接到Ghostscript图形库的PCL/PXL解释器。 GhostXPS: GhostXPS是XPS（XML Paper Specfication）文件的解释器。这包括一个连接到Ghostscript图形库的XPS解释器。 URW Font Information: urwfonts 目录中的一组truetype字体是PCL/XL解释器正常运行所必需的，但它们不是免费软件，也不是在GNU GPL/AGPL下分发的。相反，它们可以根据禁止商业用途的AFPL许可证重新分发。 Convert PDF to Images 这里使用该 input.pdf 文件作为转换研究。测试时，现将该文件保存为input.pdf。
常用参数与含义 -dBATCH: 在处理完所有在命令行中命名的文件后退出，而不是进入读取 PostScript 命令的交互式循环。相当于将-c quit放在命令行末尾。 -dNOPAUSE: 禁用提示和每页末尾的暂停。可以理解为连续打印或连续转换文件，不会在每页渲染完毕后有命令行提示出现。 -sDEVICE=: 对应不同的输出类型，可以是打印机，文件类型等 -sOutputFile=: 输出文件参数。可以使用%d或%03d作为文件模板的一部分，Ghostscript将用页码替换该部分。但请注意，并非所有设备都支持该模板。此外，由于某些设备在打开时会写入输出文件，因此可能会写入额外的空白页（pdfwrite、ps2write、eps2write、pxlmono、pxlcolor） -o: 作为输出文件的一种简写。使用该参数时，会自动设置-dBATCH和-dNOPAUSE选项。 -r: 可以使用-rXRESxYRES或-rres的格式设置输出的大小。单位： dots (or pixels) per inch -sPAPERSIZE=: Ghostscript默认使用美国信纸作为其页面大小。可以使用例如-sPAPERSIZE=a4的设置进行页面大小的调整。如果不使用这个参数，则使用下面两个参数： -dDEVICEWIDTHPOINTS=: 宽度 -dDEVICEHEIGHTPOINTS=: 高度 -dFIXEDMEDIA: 系统默认使用-sPAPERSIZE=设置页面大小，如果要启用宽度和高度设置，则需要包含该开关项。 -sPageList=: 页面范围用逗号“,”分隔。每个页面范围可以包括： 单个页码。例如： -sPageList=1,3,5 ；表示只处理1,3,5页 起始页码-结束页码。例如： -sPageList=5-10 ；表示从第5页开始，处理到第10页。 起始页码-。例如：-sPageList=12- ；表示从第12页开始，一直处理到最后一页。 -dFitPage: 此选项设置-dEPSFitPage和-dPDFFitPage选项。 -dPDFFitPage：将PDF文件缩放以适应当前设备页面大小。与-dFIXEDMEDIA选项一起使用，用于将内容调整到页面大小。 -dTextAlphaBits和-dGraphicsAlphaBits: 针对文本和图形内容分别启用抗锯齿。允许的值为1，2或4。至越小渲染越快。 dDownScaleFactor: 内部渲染在输出之前按给定的整数因子按比例缩小,取值&amp;lt;=8。 图像大小 在控制输出不同图像大小时测试发现如下两种组合：
-dDEVICEWIDTHPOINTS=w -dDEVICEHEIGHTPOINTS=h -dFIXEDMEDIA -dPSFitPage: 前三个是控制页面大小，最后一个是将内容填充到页面大小。 -rres: 可以理解为对pdf做等比例缩放。其还有另一种形式-rXRESxYRES，可以分别控制宽和高的缩放比例。例如-r100x50,则高度会被压缩到原来的50%。 这两种组合如果在对pdf输出图像时是等比例缩放，则效果相同。 gs -sDEVICE=png16m -sPageList=4 -dDEVICEWIDTHPOINTS=960 -dDEVICEHEIGHTPOINTS=720 -dFIXEDMEDIA -dPSFitPage -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png-00.%03d.png input.pdf gs -sDEVICE=jpeg -sPageList=4 -dDEVICEWIDTHPOINTS=960 -dDEVICEHEIGHTPOINTS=720 -dFIXEDMEDIA -dPSFitPage -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o jpg-00.%03d.png input.pdf Convert PDF to png -sDEVICE=png16m: 24-bit RGB color -sDEVICE=pnggray: 8-bit grayscale -sDEVICE=png256: 8-bit color -sDEVICE=png16: 4-bit color -sDEVICE=pngmono: black-and-white gs -sDEVICE=png16m -sPageList=4 -r96 -o png-01.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r96 -dTextAlphaBits=1 -dGraphicsAlphaBits=1 -o png-02.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r96 -dTextAlphaBits=2 -dGraphicsAlphaBits=2 -o png-03.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r96 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png-04.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r192 -dDownScaleFactor=2 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png-05.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r384 -dDownScaleFactor=4 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png-06.%03d.png input.pdf gs -sDEVICE=png16m -sPageList=4 -r768 -dDownScaleFactor=8 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png-07.%03d.png input.pdf 最终选择质量和大小都相对能接受的参数：
gs -sDEVICE=png16m -r96 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o png.%03d.png input.pdf Convert PDF to jpeg -sDEVICE=jpeg: JFIF standard 1.01 -sDEVICE=jpeggray: grayscale -dJPEGQ=: 该等级可平衡压缩程度与重构时图像的保真度。较低的值会从图像中丢弃更多信息以实现更高的压缩率，因此在重构时质量会降低。int, [0,100], 默认75。 -dQFactor=: Adobe的QFactor质量等级，可以使用它来代替上面的JPEGQ。float, [0.0, 1.0]。默认-dJPEGQ=75与-dQFactor=0.5等价。 gs -sDEVICE=jpeg -sPageList=4 -r96 -o jpg-01.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r96 -dTextAlphaBits=1 -dGraphicsAlphaBits=1 -o jpg-02.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r96 -dTextAlphaBits=2 -dGraphicsAlphaBits=2 -o jpg-03.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r96 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o jpg-04.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r192 -dDownScaleFactor=2 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o jpg-05.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r384 -dDownScaleFactor=4 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o jpg-06.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r768 -dDownScaleFactor=8 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o jpg-07.%03d.jpg input.pdf gs -sDEVICE=jpeg -sPageList=4 -r192 -dDownScaleFactor=2 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dQFactor=70 -o jpg-08.%03d.jpg input.pdf 最终选择质量和大小相对能接受的参数：
gs -sDEVICE=jpeg -r192 -dDownScaleFactor=2 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -o 01.%03d.jpg input.pdf Show PDF -dBATCH: 在处理完所有在命令行中命名的文件后退出，而不是进入读取 PostScript 命令的交互式循环。相当于将-c quit放在命令行末尾。 gs -dBATCH input.pdf Reference Console Options Devices</content></entry><entry><title>Classification</title><url>/posts/202211/03-classification/</url><categories><category>machine-learning</category></categories><tags><tag>classification</tag></tags><content type="html"><![CDATA[Classification: Given options(classes), the function outputs the correct one.
Probabilistic Generative Model features and predict target 一共有7个features，其中 Total = HP + Attack + Deffense + SP Atk + Sp Def + Speed predict target: type of pokemon features and predict target How to do Classification 收集Training data for Classification 考虑如果做分类？ Classification as Regression?（分类问题是否可以用回归算法处理？） 以二分类举个例子
Training: Class 1 means the target is 1; Class 2 means the target is -1 Testing: $ \text{closer to 1} \rightarrow \text{class 1}; \text{closer to -1} \rightarrow \text{class 2} $ 这样直接用Regression来解决Classification的问题，会发生如下图的情况：
当样本feature如左图所示，则$y=b+w_1x_1+w_2x_2$的函数可以很好的工作。 当样本feature如右图所示，由于右下角的数据，导致Regression的Loss函数在求最小值时，会倾向于给出紫色的线段的方程。即Loss函数会由于“太正确”而导致最终预测结果出错。 Penalize to the examples that are &ldquo;too correct&rdquo; &hellip; (Bishop, P186) Classification as Regression Ideal Alternatives(理想的做法) Function (Model): $$ \delta(x) \Rightarrow \begin{cases} g(x) &gt; 0 &amp; \text{Output = class 1} \cr else &amp; \text{Output = class 2} \end{cases} $$ Loss Function The number of times f get incorrect results on training data. $$ L(f) = \sum_n\delta(f(x^n) \ne \hat{y}^n ) $$ Find the best function: Example: Perceptron, SVM Generative Model $P(C_1)$是从两个分类中，随机选中Class1的几率，$P(C_2)$是从两个分类中，随机选中Class2的几率。 假设x为其中一种颜色的圆圈，则：$P(x|C_1)$表示从Class1中选中x的几率，$P(x|C_2)$表示从Class2中选中x的几率， 选中x属于class1的几率就是：$ P(C_1|x) = \frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)} $ 选中x的总几率就是： $ P(x) = P(x|C_1)P(C_1) + P(x|C_2)P(C_2) $ Estimating the Probabilities From training data, 这整个想法就叫做Generative Model Generative Model Gaussian Distribution $ f_{\mu,\sum}(x) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\sum|^{1/2}} exp \{ -\frac{1}{2}(x-\mu)^T\sum^{-1}(x-\mu) \} $ input: vector x, output: probability of sampling x(实际是probability density，概率密度与概率成正比,此处简略为概率) The shape of the function determines by mean $\mu$ and covariance matrix $\sum$(协方差矩阵) Gaussian Distribution Maximum Likelihood（找mean$\mu$和covariance matrix $\Sigma$的方法） mean $\mu$控制原点的位置。 covariance matrix $\Sigma$决定图形的形状。 虽然图中左下角的点都可以求出相对于两个圈的概率，但是这两个概率的大小是不一样的。 给定一个Gaussian的$\mu$和$\Sigma$,就可以求出对应的Likelihood: $ L(\mu, \Sigma) = f_{\mu, \Sigma}(x^1)f_{\mu, \Sigma}(x^2)f_{\mu, \Sigma}(x^3)\dots\dots f_{\mu, \Sigma}(x^n) $ 这里的每一个$f_{\mu, \Sigma}(x^1)$展开，都是$ f_{\mu,\sum}(x) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\sum|^{1/2}} exp \{ -\frac{1}{2}(x-\mu)^T\sum^{-1}(x-\mu) \} $ Maximum Likelihood: $ \mu^*, \Sigma^* = arg \max\limits_{\mu, \Sigma} L(\mu, \Sigma) $ $\mu^*$为取x的平均值: $ \mu^* = \frac{1}{n}\sum\limits_{i=1}^n x^i $ $ \Sigma^* = \frac{1}{n} \sum\limits_{i=1}^n(x^i-\mu^*)(x^i-\mu^*)^T $ Maximum Likelihood 采用上诉方法得到的测试结果 features $\theta$ test accuracy Defense,SP Defense $ \mu^1, \mu^2 $ : 2-dim vector $\Sigma^1, \Sigma^2$: 2*2 matrices 47% All the 7 features $ \mu^1\dots\mu^7 $ : 7-dim vector $\Sigma^1\dots\Sigma^7$: 7*7 matrices 54% 结果不理想，需要重新调整模型。 Modifying Model (Ref: Bishop chapter 4.2.2) 给每一个Gaussian有一个自己的$\mu$和自己的covariance matrix $\Sigma$是很少见的 常见的做法是，不同的Class对应的Gaussian可以share相同的covariance matrix $\Sigma$ Share Covariance matrix 模型修改后如何计算$\mu$和$\Sigma$ 假设有数量为n的class1,数量为m的class2 likelihood: \begin{align} L(\mu^1, \mu^2, \Sigma) = &amp; f_{\mu^1, \Sigma}(x^1)f_{\mu^1, \Sigma}(x^2)\dots\dots f_{\mu^1, \Sigma}(x^n) \cr \times &amp;f_{\mu^2, \Sigma}(x^{n+1})f_{\mu^2, \Sigma}(x^{n+2})\dots\dots f_{\mu^2, \Sigma}(x^{n+m}) \end{align} 如下图， $\mu^1$, $\mu^2$和原来一样计算: \begin{align} \mu^1 &amp; = \frac{1}{n}\sum\limits_{i=1}^n x^i \cr \mu^2 &amp; = \frac{1}{m}\sum\limits_{i=1}^m x^i \end{align} $\Sigma^*$的计算修改为：$ \Sigma = \frac{n}{n+m}\Sigma^1 + \frac{m}{n+m}\Sigma^2 $ Compute 模型修改后画出的图形 从原来的曲线，变成了一条直线 由于边界(boundary)是一条直线，所以这种模型也叫做Linear Model。 在这个模型下，考虑所有的7个features进行计算，则accuracy从原来的54%上升到73% 总结一下3个步骤 Function Set(Model): \begin{align} P(C_1|x) &amp;= \frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)} \cr &amp; \begin{cases} \text{if} P(C_1|x) &gt; 0.5 &amp; \text{, output: class 1} \cr Otherwise &amp; \text{, output: class 2} \end{cases} \end{align} Goodness of a function: The mean $\mu$ and covariance $\Sigma$ that maximizing the likelihood(the probability of generating data) Find the best function: easy Probability Distribution You can always use the distribution you like 假设$P(x|C^1)$构成Class1的x有K个，且K个x想对于Class1的几率是独立的，则：$ P(x|C1) = P(x_1|C_1)P(x_2|C_1)\cdots P(x_K|C_1) $，这个会得到1-D Gaussian,参数会进一步简化 For binary features, you may assume they are from Bernouli distributions. If you assume all the dimensions are independent, then you are using Naive Bayes Classifier. Posterior Probability 设有表达式(1)上下同时除上表达式$ P(C_1)P(x|C_1) $得到表达式(2) 设$ z = ln\frac{P(C_1)P(x|C_1)}{P(C_2)P(x|C_2)} $,则表达式(2)变为表达式(3) 表达式(3)和(4)等价，为Sigmoid Function \begin{align} P(C_1|x) &amp;= \frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)} \tag{1} \cr &amp;= \frac{1}{1+\frac{P(C_2)P(x|C_2)}{P(C_1)P(x|C_1)}} \tag{2} \cr &amp;= \frac{1}{1 + exp^{-z}} \tag{3} \cr &amp;= \sigma(z) \tag{4} \end{align} 求z 设$N_1$是Class1出现的次数，$N_2$是Class2出现的次数 表达式(3)和(4)为Gaussian的Distribution 表达式(5)上下同时除以$\frac{1}{(2\pi)^{D/2}}$得到表达式(6) \begin{align} z &amp;= ln\frac{P(C_1)P(x|C_1)}{P(C_2)P(x|C_2)} \cr &amp;= ln\frac{P(C_1)}{P(C_2)} + ln\frac{P(x|C_1)}{P(x|C_2)} \tag{1} \cr ln\frac{P(C_1)}{P(C_2)} &amp;=\frac{\frac{N_1}{N_1+N_2}}{\frac{N_2}{N_1+N_2}} = \frac{N_1}{N_2} \tag{2} \cr P(x|C_1) &amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma^1|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) \} \tag{3} \cr P(x|C_2) &amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma^2|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2) \} \tag{4} \cr
ln\frac{P(x|C_1)}{P(x|C_2)} &amp;= ln\frac{\frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma^1|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) \}} {\frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma^2|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2) \}} \tag{5} \cr &amp;= ln\frac{\frac{1}{|\Sigma^1|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) \}} {\frac{1}{|\Sigma^2|^{1/2}} exp \{ -\frac{1}{2}(x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2) \}} \tag{6} \cr &amp;= ln\frac{|\Sigma^2|^{1/2}}{|\Sigma^1|^{1/2}}exp \{ -\frac{1}{2}[(x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) - (x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2)] \} \tag{7} \cr &amp;= ln\frac{|\Sigma^2|^{1/2}}{|\Sigma^1|^{1/2}} - \frac{1}{2}[(x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) - (x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2)] \tag{8} \cr (x-\mu^1)^T(\Sigma^1)^{-1}(x-\mu^1) &amp;= x^T(\Sigma^1)^{-1}x - x^T(\Sigma^1)^{-1}\mu^1 - (\mu^1)^T(\Sigma^1)^{-1}x + (\mu^1)^T(\Sigma^1)^{-1}\mu^1 \cr &amp;= x^T(\Sigma^1)^{-1}x - 2(\mu^1)^T(\Sigma^1)^{-1}x + (\mu^1)^T(\Sigma^1)^{-1}\mu^1 \cr (x-\mu^2)^T(\Sigma^2)^{-1}(x-\mu^2) &amp;= x^T(\Sigma^2)^{-1}x - 2(\mu^2)^T(\Sigma^2)^{-1}x + (\mu^2)^T(\Sigma^2)^{-1}\mu^2 \cr z &amp;= ln\frac{|\Sigma^2|^{1/2}}{|\Sigma^1|^{1/2}} - \frac{1}{2}x^T(\Sigma^1)^{-1}x + (\mu^1)^T(\Sigma^1)^{-1}x - \frac{1}{2}(\mu^1)^T(\Sigma^1)^{-1}\mu^1 \cr &amp;+ \frac{1}{2}x^T(\Sigma^2)^{-1}x - (\mu^2)^T(\Sigma^2)^{-1}x + \frac{1}{2}(\mu^2)^T(\Sigma^2)^{-1}\mu^2 + ln\frac{N_1}{N_2} \end{align} 求 $\sigma(z)$ 当$ \Sigma_1 = \Sigma_2 = \Sigma $时，表达式(1)变为表达式(2) 设: $ w^T = (\mu_1 - \mu_2)^T\Sigma^{-1} $以及$ b = -\frac{1}{2}(\mu^1)^T(\Sigma^1)-1\mu^1 + \frac{1}{2}(\mu^2)^T(\Sigma^2)-1\mu^2 + ln\frac{N_1}{N_2} $则(2)可以推导为(3) In generative model, we estimate $ N_1, N_2, \mu^1, \mu^2, \Sigma $, then we have w and b. \begin{align} z &amp;= ln\frac{|\Sigma^2|^{1/2}}{|\Sigma^1|^{1/2}} - \frac{1}{2}x^T(\Sigma^1)^{-1}x + (\mu^1)^T(\Sigma^1)^{-1}x - \frac{1}{2}(\mu^1)^T(\Sigma^1)^{-1}\mu^1 \cr &amp;+ \frac{1}{2}x^T(\Sigma^2)^{-1}x - (\mu^2)^T(\Sigma^2)^{-1}x + \frac{1}{2}(\mu^2)^T(\Sigma^2)^{-1}\mu^2 + ln\frac{N_1}{N_2} \tag{1}\cr &amp;= (\mu_1 - \mu_2)^T\Sigma^{-1}x -\frac{1}{2}(\mu^1)^T(\Sigma^1)-1\mu^1 + \frac{1}{2}(\mu^2)^T(\Sigma^2)-1\mu^2 + ln\frac{N_1}{N_2} \tag{2}\cr &amp;= w \cdot x + b \tag{3} \cr P(C_1|x) &amp;= \sigma(z) \cr &amp;= \sigma(w \cdot x + b) \end{align} How about directly find w and b? reference video ]]></content></entry><entry><title>Regression</title><url>/posts/202211/02-regression/</url><categories><category>machine-learning</category></categories><tags><tag>regression</tag></tags><content type="html"><![CDATA[Regression: Input a vector, the function outputs a scalar.
使用简单模型 预测问题：根据前面的浏览数据，预测后面的浏览量
Function with Unknown Parameters Model: $y = b + wx_1$ $y$(Label): no. of views on 2/26， $x_1$(feature): no. of views on 2/25 $w$(weight) and $b$(bias) are unknown parameters (learned from data) Define Loss from Training Data Loss is a function of parameters: $L(b, w)$ Loss: how good a set of values is. Loss: $ L = \frac{1}{N}\sum\limits_{n=1}^N e_n$ $e = |y - \hat{y}|$ $L$ is mean absolute error (MAE) $e = (y-\hat{y})^2$ $L$ is mean square error (MSE) if $y$ and $\hat{y}$ are both probability distributions, then use Cross-Entropy 使用不同的参数，计算出来的Loss画出来的等高线图叫做：Error Surface 等高线图: Error Surface Optimization 找一个$w$和$b$，使$L$最小： $ w^*, b^* = arg \min\limits_{w, b} L$ 这种找到最小$w$和$b$的方法叫做：Gradient Descent
简述Gradient Descent过程 以一个参数$w$为例描述Gradient Descent的过程:
随机初始化点$w^0$ 计算$w=w^0$时，对$L$的微分是多少：$\frac{{\partial}L}{{\partial}W}|_{w=w^0}$ 如果计算出来的结果为负数，则增加$w$ 如果计算出来的结果为正数，则减少$w$ 增加或减少的数值为：${\color{red}\eta}\frac{{\partial}L}{{\partial}W}|_{w=w^0}$, $\color{red}\eta$:叫learning rate,是一个hyperparameter 这个过程用的数学表达式是：$ w^1 \leftarrow w^0 - {\color{red}\eta}\frac{{\partial}L}{{\partial}W}|_{w=w^0} $ 重复上述步骤不断更新$w$。两种状况会停下来: 更新的次数达到预设值 微分为0 Gradient Descent 当两个参数$w$, $b$时:
随机初始化$w^0$, $b^0$ 计算两个微分值 $ \frac{\partial L}{\partial w}|_{w=w^0, b=b^0} $ 用$w$的微分更新$w$的值 $ w^1 \leftarrow w^0 - {\color{red}\eta}\frac{\partial L}{\partial w}|_{w=w^0, b=b^0} $ $ \frac{\partial L}{\partial b}|_{w=w^0, b=b^0} $ 用$b$的微分更新$b$的值 $ b^1 \leftarrow b^0 - {\color{red}\eta}\frac{\partial L}{\partial b}|_{w=w^0, b=b^0} $ Update $w$ and $b$ interatively 使用单参数的多个连续的历史记录 通过观察资料发现数据有7天为一个周期，所以使用新的公式进行调整, 并得到下面数据：
days function training loss testing loss 1 $ y = b + wx_{\color{red}1} $ $ L = 0.48k $ $ L&rsquo; = 0.58k $ 7 $ y = b + \sum\limits_{j=1}^{\color{red}7}w_jx_j $ $ L = 0.38k $ $ L&rsquo; = 0.49k $ 28 $ y = b + \sum\limits_{j=1}^{\color{red}28}w_jx_j $ $ L = 0.33k $ $ L&rsquo; = 0.46k $ 56 $ y = b + \sum\limits_{j=1}^{\color{red}56}w_jx_j $ $ L = 0.32k $ $ L&rsquo; = 0.46k $ 上述模型有个共同的名字Linear Models
调整模型参数，观察Training Loss和Testing Loss的变化，挑选合适的模型 名词解释 hyperparameter: 需要人来设置的参数
local minima: 局部最小值
global minima: 全局最小值
总结Machine Learning训练的简单步骤 function with unknown define loss from training data optimization 打破模型局限 不同的w和不同的b对Linear Models的影响如蓝色线。红色表示可能的真实趋势。这种来自于Model的限制叫做Model Bias。 Linear Models的局限性 All Piecewise Linear Curves All Piecewise Linear Curves = constant + sum of a set of Hard Sigmoid Piecewise Linear Curves sigmoid \begin{align*} y &amp;= {\color{red}c}\frac{1}{1+e^{-({\color{green}b}+{\color{blue}w}x_1)}} \cr &amp;= {\color{red}c}\,sigmoid({\color{green}b}+{\color{blue}w}x_1) \end{align*}
调整$ {\color{blue}w}, {\color{green}b}, {\color{red}c} $对应的函数图像 Sigmoid Parameters 相对于红色线段，可以用多个Sigmoid函数组合出来，将0:constant和1,2,3sigmoid加起来就是红色线段
\begin{align*} b\tag{0}\cr {\color{red}c_1}\,sigmoid({\color{green}b_1}+{\color{blue}w_1}x_1)\tag{1}\cr {\color{red}c_2}\,sigmoid({\color{green}b_2}+{\color{blue}w_2}x_1)\tag{2}\cr {\color{red}c_3}\,sigmoid({\color{green}b_3}+{\color{blue}w_3}x_1)\tag{3}\cr \textcolor{red}{\text{red curve}}\text{ will be:} \cr y = b + \sum_{i=1}^3{\color{red}c_i}\,sigmoid({\color{green}b_i}+{\color{blue}w_i}x1) \end{align*}
Sigmoid Parameters 基于sigmoid的模型，对原来的模型进行调整如下： \begin{align*} y &amp;= b+wx_1 \cr &amp; \Downarrow \cr y &amp;= b + \sum_{i=1}^n {\color{red}c_i} \, sigmoid({\color{green}b_i}+{\color{blue}w_i}x_i) \cr y &amp;= b + \sum_{j=1}^m w_jx_j \cr &amp; \Downarrow \cr y &amp;= b + \sum_{i=1}^n {\color{red}c_i} \, sigmoid({\color{green}b_i}+\sum_{j=1}^m{\color{blue}w_{ij}}x_j) \end{align*}
使$n=3, m=3$对表达式$y = b + \sum_{i=1}^n {\color{red}c_i} \, sigmoid({\color{green}b_i}+\sum_{j=1}^m{\color{blue}w_{ij}}x_j)$进行展开 \begin{align*} r_1 &amp;= {\color{green}b_1} + {\color{blue}w_{11}}x_1 + {\color{blue}w_{12}}x_2 + {\color{blue}w_{13}}x_3 \cr r_2 &amp;= {\color{green}b_2} + {\color{blue}w_{21}}x_1 + {\color{blue}w_{22}}x_2 + {\color{blue}w_{23}}x_3 \cr r_3 &amp;= {\color{green}b_3} + {\color{blue}w_{31}}x_1 + {\color{blue}w_{32}}x_2 + {\color{blue}w_{33}}x_3 \cr &amp;\Downarrow \cr \begin{bmatrix} r_1 \cr r_2 \cr r_3 \end{bmatrix} &amp;= \begin{bmatrix} {\color{green}b_1} \cr {\color{green}b_2} \cr {\color{green}b_3} \end{bmatrix} + \begin{bmatrix} {\color{blue}w_{11}} &amp; {\color{blue}w_{12}} &amp; {\color{blue}w_{13}} \cr {\color{blue}w_{21}} &amp; {\color{blue}w_{22}} &amp; {\color{blue}w_{23}} \cr {\color{blue}w_{31}} &amp; {\color{blue}w_{32}} &amp; {\color{blue}w_{33}} \cr \end{bmatrix} \begin{bmatrix} x_1 \cr x_2 \cr x_3 \end{bmatrix} \end{align*}
其中$\color{red}\sigma$表示sigmoid表达式 Sigmoid 展开图示 如下图所示，x为feature；而所有的$W, {\color{green}b}, c^T, b$作为unknown parameters展开为一个长的一维向量，定义为$\color{red}\theta$ unknown parameters Loss function Loss is a function of parameters $L(\theta)$ Loss means how good a set of values is. Optimization of New Model $ \theta^* = arg\,\min\limits_\theta L$
(Randomly) Pick initial values $\theta^0$ 对所有参数$\theta$对$L$做微分，这里的$g$叫做gradient \begin{align} gradient \Leftarrow g &amp;= \begin{bmatrix} {\frac{\partial L}{\partial\theta_1}|_{\theta=\theta^0}} \cr {\frac{\partial L}{\partial\theta_2}|_{\theta=\theta^0}} \cr \vdots \end{bmatrix} \cr g &amp;= \nabla L(\theta^0) \end{align} 然后进行参数更新 $$ \begin{bmatrix} \theta_1^1 \cr \theta_2^1 \cr \vdots \end{bmatrix} \leftarrow \begin{bmatrix} \theta_1^0 \cr \theta_2^0 \cr \vdots \end{bmatrix} - \begin{bmatrix} {\color{red}\eta}\frac{\partial L}{\partial\theta_1}|_{\theta=\theta^0} \cr {\color{red}\eta}\frac{\partial L}{\partial\theta_2}|_{\theta=\theta^0} \cr \vdots \end{bmatrix} $$ $$ \theta^1 \leftarrow \theta^0 - {\color{red}\eta}g $$ Compute gradient $ g = \nabla L(\theta^0) $ 全部资料是$L$,批次编号为$L^1, L^2, L^3$。batch是进行参数更新的单位，即一个批次进行一次参数更新；epoch表示所有批次全部执行了参数更新。
batch and epoch 使用$ Sigmoid \rightarrow ReLU $ Rectified Linear Unit (ReLU): $ {\color{red}c}\,max(0, {\color{green}b} + {\color{blue}w}x_1) $ 类似sigmoid和ReLU的函数在机器学习中叫做Activation function 1个sigmoid图形需要2个ReLU来表示 作个数不同的ReLU only one layer input features are the no. of views in the past 56 days model training loss testing loss linear 0.32k 0.46k 10ReLU 0.32k 0.45k 100ReLU 0.28k 0.43k 1000ReLU 0.27k 0.43k 作多层ReLU 100 ReLU for each layer input features are the no. of views in the past 56 days Better on training data, worse on unseen data: Overfitting , see layer count 4. layer count training loss testing loss 1 0.28k 0.43k 2 0.18k 0.39k 3 0.14k 0.38k 4 0.10k 0.44k Backpropagation Backpropgation: an efficient way to compute $\sfrac{\partial L}{\partial w}$
Gradient Descent 对每一个参数针对L进行偏微分得到: $\nabla L(\theta)$ 使用batch的数据对参数$\theta$进行更新. Gradient Descent Chain Rule case 1: $\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$ case 2: $\frac{dz}{ds}=\frac{dz}{dx}\frac{dx}{ds}+\frac{dz}{dy}\frac{dy}{ds}$ Chain Rule Forward and Backward pass: Forward pass: Compute $\sfrac{\partial z}{\partial w}$for all parameters Backward pass: Compute $\sfrac{\partial C}{\partial z}$ for all activation function inputs z Forward and Backward pass Regularization Regularization出现的背景：当原始数据有过多的feature和模型有大量的w，可能存在某些feature确实与最终的结果无关，在这种情况下可以先将所有feature包含进来，然后通过Regularization的思路对w进行优化，从而降低无效feature对最终结果的影响。
假设Model Function为$ y = b + \sum w_i x_i $ 原来定义的Loss Function为$ L = \sum\limits_n( \hat{y}^n - ( b + \sum w_i x_i ) )^2$ Regularization既是在上面Loss Function的基础上加上红色部分: $ L = \sum\limits_n( \hat{y}^n - ( b + \sum w_i x_i ) )^2 + \color{red}\lambda\sum(w_i)^2$ The functions with smaller $w_i$ are better Why smooth functions are preferred? If some noises corrupt input $x_i$ when testing. A smoother function has less influence. 因为在进行预测时，有噪音输入的情况下，越smooth的function对输出造成的影响越不敏感。 其中的$\lambda$也是一个hyperparameter 当我们调整$\lambda$的值，观察Loss的变化是，我们可以观察到如下信息：
$\lambda$越大时，Regularization项影响就越大，整个function就越平滑 Training随着$\lambda$的增加而增加 Testing随着$\lambda$的增加先减少再增加 We prefer smooth function, but don&rsquo;t be too smooth. 所以$\lambda$的选择值选择在Testing的Loss的转折点处 Regularization Loss Reference Video ]]></content></entry><entry><title>Mpv常用配置</title><url>/posts/202211/mpv-config/</url><categories><category>blog</category></categories><tags><tag>mpv</tag></tags><content type="html"><![CDATA[配置文件位置 系统范围的配置文件&rsquo;mpv.conf&rsquo;位于您的配置目录中（例如 /etc/mpv 或 /usr/local/etc/mpv）。 用户特定的文件是~/.config/mpv/mpv.conf。 有关详细信息和平台细节（特别是 Windows 路径），请参阅文件部分。
用户特定的选项会覆盖系统范围的选项，而命令行上给出的选项也会覆盖。配置文件的语法是 option=value。 #之后的所有内容都被视为注释。可以通过将它们设置为 yes 来启用没有值的选项，并通过将它们设置为 no 来禁用它们。
Screenshot常用配置 screenshot-format=&#34;jpg&#34; screenshot-template=&#34;%F%n&#34; screenshot-directory=&#34;~/Pictures/mpv-shot&#34; screenshot-jpeg-quality=70 screenshot-png-compression=9 screenshot-format 设置用于保存屏幕截图的图像文件类型。png, jpg(default), jpeg, webp, jxl
screenshot-template 指定用于保存屏幕截图的文件名模板。模板指定没有文件扩展名的文件名，并且可以包含格式说明符，在截屏时将被替换。 默认情况下，模板是 mpv-shot%n，这会产生像mpv-shot0012.png这样的文件名。
模板可以以相对或绝对路径开头，以指定应保存屏幕截图的目录位置。
如果最终的屏幕截图文件名指向一个已经存在的文件，则该文件不会被覆盖。屏幕截图将不会被保存，或者如果模板包含%n，则使用不同的新生成的文件名保存。
%[#][0X]n 一个序列号，用零填充到长度X（默认值：04）。例如。传递格式%04n将在第12个屏幕截图中产生0012。 每次截取屏幕截图或文件已存在时，该数字都会增加。长度X必须在0-9范围内。使用可选的#符号，mpv将使用最低的可用编号。 例如，如果您截取三张截图——0001、0002、0003——并删除前两张，那么接下来的两张截图将不再是0004和0005，而是再次成为0001和0002。
%f 当前播放视频的文件名。
%F 与 %f 相同，但去掉文件扩展名，包括点。
%x 当前播放视频的目录路径。如果视频不在文件系统上（但例如 http://），则扩展为空字符串。
%X{fallback} 与 %x 相同，但如果视频文件不在文件系统上，则返回 {&hellip;} 内的后备字符串。
%p 当前播放时间，与 OSD 中使用的格式相同。结果是“HH:MM:SS”形式的字符串。例如，如果视频的时间位置为 5 分 34 秒，则 %p 将替换为“00:05:34”。
%P 与 %p 类似，但以毫秒为单位延长播放时间。它的格式为“HH:MM:SS.mmm”，其中“mmm”是播放时间的毫秒部分。
%wX 使用格式字符串 X 指定当前播放时间。%p 类似于 %wH:%wM:%wS，%P 类似于 %wH:%wM:%wS.%wT。
有效的格式说明符:
%wH 小时（用 0 填充到两位数） %wh 小时（无填充） %wM 分钟 (00-59) %wm 总分钟数（包括小时数，与 %wM 不同） %wS 秒 (00-59) %ws 总秒数（包括小时和分钟） %wf 像 %ws，但返回的是浮点数 %wT 毫秒 (000-999) %tX 使用格式X指定当前本地日期/时间。此格式说明符在内部使用 UNIX strftime() 函数，并将传递“%X”的结果插入 strftime。 例如，%tm 将插入当前月份的数字作为数字。您必须使用多个 %tX 说明符来构建完整的日期/时间字符串。
%{prop[:fallback text]} 插入输入属性“prop”的值。例如。 %{filename} 与 %f 相同。如果该属性不存在或不可用，则插入错误文本，除非指定了回退。
%% 替换为 % 字符本身。
screenshot-directory 将屏幕截图存储在此目录中。此路径与&ndash;screenshot-template生成的文件名相连。如果模板文件名已经是绝对的，则忽略该目录。
如果该目录不存在，则在第一个屏幕截图中创建该目录。如果不是目录，尝试写截图时会报错。
默认情况下未设置此选项，因此会将屏幕截图写入启动 mpv 的目录。在伪 gui 模式下, 它被设置为桌面。
screenshot-png-compression=&lt;0-9&gt; 设置PNG压缩级别。更高意味着更好的压缩。这会影响截图文件大小和写截图的时间。过高的压缩可能会占用过多的CPU时间并中断播放。默认值为7。
screenshot-jpeg-quality=&lt;0-100&gt; 设置 JPEG 质量级别。更高意味着更好的质量。默认值为 90。
参考 configuration-files screenshot ]]></content></entry><entry><title>Mpv快捷键</title><url>/posts/202211/mpv-keyboard/</url><categories><category>blog</category></categories><tags><tag>mpv</tag></tags><content type="html"><![CDATA[Seek backward/forward 5 seconds LEFT and RIGHT Seek backward/forward 5 seconds. Shift+arrow does a 1 second exact seek (see --hr-seek). Seek forward/backward 1 minute UP and DOWN Seek forward/backward 1 minute. Shift+arrow does a 5 second exact seek (see --hr-seek). Seek to the previous/next subtitle Ctrl+LEFT and Ctrl+RIGHT Seek to the previous/next subtitle. Subject to some restrictions and might not always work; see sub-seek command. Adjust subtitle delay Ctrl+Shift+Left and Ctrl+Shift+Right Adjust subtitle delay so that the next or previous subtitle is displayed now. This is especially useful to sync subtitles to audio. Decrease/increase speed by 10% [ and ] Decrease/increase current playback speed by 10%. Halve/double speed { and } Halve/double current playback speed. Reset speed BACKSPACE Reset playback speed to normal. Undo the last seek Shift+BACKSPACE Undo the last seek. This works only if the playlist entry was not changed. Hitting it a second time will go back to the original position. See revert-seek command for details. Mark the current position Shift+Ctrl+BACKSPACE Mark the current position. This will then be used by Shift+BACKSPACE as revert position (once you seek back, the marker will be reset). You can use this to seek around in the file and then return to the exact position where you left off. backward/forward playlist &lt; and &gt; Go backward/forward in the playlist. Go forward playlist. ENTER Go forward in the playlist. Pause p / SPACE Pause (pressing again unpauses). Step forward. . Step forward. Pressing once will pause, every consecutive press will play one frame and then go into pause mode again. Step backward , Step backward. Pressing once will pause, every consecutive press will play one frame in reverse and then go into pause mode again. quit q Stop playing and quit. Q Like q, but store the current playback position. Playing the same file later will resume at the old playback position if possible. Decrease/increase volume / and * Decrease/increase volume. 9 and 0 Decrease/increase volume. Mute m Mute sound. Cycle play _ Cycle through the available video tracks. # Cycle through the available audio tracks. fullscreen f Toggle fullscreen (see also &ndash;fs).
Exit fullscreen ESC Exit fullscreen mode. stay-on-top T Toggle stay-on-top (see also --ontop). Decrease/increase pan-and-scan w and W Decrease/increase pan-and-scan range. The e key does the same as W currently, but use is discouraged. Show progression bar o (also P) Show progression bar, elapsed time and total duration on the OSD. Toggle OSD states O Toggle OSD states between normal and playback time/duration. Toggle subtitle v Toggle subtitle visibility. Cycle through the available subtitles j and J Cycle through the available subtitles. Adjust subtitle delay z and Z Adjust subtitle delay by +/- 0.1 seconds. The x key does the same as Z currently, but use is discouraged. Set/clear loop points l Set/clear A-B loop points. See ab-loop command for details. infinite looping L Toggle infinite looping. Adjust audio delay Ctrl + and Ctrl - Adjust audio delay (A/V sync) by +/- 0.1 seconds. Adjust subtitle font size Shift+g and Shift+f Adjust subtitle font size by +/- 10%. subtitles ass overrides u Switch between applying no style overrides to SSA/ASS subtitles, and overriding them almost completely with the normal subtitle style. See --sub-ass-override for more info. subtitle VSFilter aspect compatibility mode V Toggle subtitle VSFilter aspect compatibility mode. See --sub-ass-vsfilter-aspect-compat for more info. Move subtitles up/down r and R Move subtitles up/down. The t key does the same as R currently, but use is discouraged. screenshot s Take a screenshot. S Take a screenshot, without subtitles. (Whether this works depends on VO driver support.) Ctrl s Take a screenshot, as the window shows it (with subtitles, OSD, and scaled video). Seek to the beginning of the previous/next chapter PGUP and PGDWN Seek to the beginning of the previous/next chapter. In most cases, &quot;previous&quot; will actually go to the beginning of the current chapter; see --chapter-seek-threshold. Seek backward or forward by 10 minutes Shift+PGUP and Shift+PGDWN Seek backward or forward by 10 minutes. (This used to be mapped to PGUP/PGDWN without Shift.) Activate/deactivate deinterlacer d Activate/deactivate deinterlacer. Cycle aspect ratio A Cycle aspect ratio override. hardware video decoding Ctrl h Toggle hardware video decoding on/off. Move the video rectangle Alt+LEFT, Alt+RIGHT, Alt+UP, Alt+DOWN Move the video rectangle (panning). changes video zoom Alt + and Alt - Combining Alt with the + or - keys changes video zoom. Reset pan/zoom Alt+BACKSPACE Reset the pan/zoom settings. Show the playlist F8 Show the playlist and the current position in it (useful only if a UI window is used, broken on the terminal). Show the list of audio and subtitle streams F9 Show the list of audio and subtitle streams (useful only if a UI window is used, broken on the terminal). displaying statistics i and I Show/toggle an overlay displaying statistics about the currently playing file such as codec, framerate, number of dropped frames and so on. See STATS for more information. Cycle OSC del Cycle OSC visibility between never / auto (mouse-move) / always Show console ` Show the console. (ESC closes it again. See CONSOLE.) ref mpv manual ]]></content></entry><entry><title>关于我</title><url>/about.html</url><categories/><tags/><content type="html">#TODO</content></entry><entry><title>Docker Command</title><url>/posts/202211/docker-command/</url><categories/><tags/><content type="html">Docker Removing Removing Images by ID or Name docker rmi &amp;lt;id&amp;gt; Docker Image Prune Removes All Dangling Images
docker image prune -a Docker System Prune 查找和删除所有未使用的对象
docker system prune -a</content></entry><entry><title>初始化pi4环境</title><url>/posts/202107/init-pi4-env/</url><categories/><tags/><content type="html">更新环境 sudo apt update sudo apt upgrade
安装docker Add Docker’s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg set up the stable repository echo &amp;#34;deb [arch=arm64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) stable&amp;#34; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null Install Docker Engine sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 配置docker权限 创建 docker 组(可选，nano中已包含docker组) 将当前用户添加到 docker 组中 激活组变化 sudo groupadd docker sudo usermod -aG docker $USER newgrp docker install frpc create frpc.ini file sudo mkdir /etc/frp cd /etc/frp sudo nano frpc.ini add under line:
[common] server_addr = xxx.xx.xx.xx server_port = 7000 [pi-CM4-IO-POE-BOX-B-test] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6981 start frpc docker run --restart=always --network host -d -v /etc/frp/frpc.ini:/etc/frp/frpc.ini --name frpc snowdreamtech/frpc install golang sudo tar -C /usr/local -xzf go1.16.5.linux-arm64.tar.gz 添加下面语句到.profile中
export PATH=$PATH:/usr/local/go/bin</content></entry><entry><title>分析Ubuntu Arm64 Docker Build</title><url>/posts/202011/how-to-build-ubuntu-arm64-docker/</url><categories/><tags/><content type="html">Ubuntu的Arm64 Docker Image项目在： docker-brew-ubuntu-core 该项目需要配合 Jenkins pipe line 文件执行。
文件首先删除 docker-brew-ubuntu-core 工程的对应arm64分支dist-amd64，并重新创建该分支，在该分支各ubuntu版本下创建Dockerfile，下载构造文件并归档到git仓库。
具体参考： docker-brew-ubuntu-core 最后，docker下官方提供的arm64的资源在 arm64v8 用户下。
另一个优质的docker arm资源在 balena.io ,项目地址在 balena-io-library jetson-xavier</content></entry><entry><title>在Pi4上编译ffmpeg支持硬件编解码以及测试和使用方法</title><url>/posts/202011/build-ffmpeg-under-pi4/</url><categories/><tags/><content type="html"><![CDATA[由于某些原因，需要在raspberry pi 4上编译最新版本ffmpeg，下面是方法以及测试方案。
编译准备 sudo apt update sudo apt upgrade 安装必要的工具和库 sudo apt install build-essential yasm pkg-config libx264-dev 下载源代码并编译 # 下载并解压 wget http://ffmpeg.org/releases/ffmpeg-snapshot-git.tar.bz2 tar jxvf ffmpeg-snapshot-git.tar.bz2 cd ffmpeg # 切换到明确的tag并创建分支 git checkout tags/n4.3.1 -b b4.3.1 ./configure --enable-gpl --enable-libx264 --enable-mmal --enable-omx --enable-omx-rpi ## pi4 2G上大约需要14分钟左右，请注意cpu散热 make -j4 sudo make install 测试rtsp h.264，1080p的cpu解码，并每5s保存一张图片 ffmpeg -rtsp_transport tcp -nostdin -loglevel error -i rtsp://username:password@ip -filter:v fps=fps=1/5 test_%03d.jpg 通过 bcmstat 软件观察，cpu消耗每路17%,内存消耗较少，约60MB。
测试rtsp h.264，1080p硬解，并每5s保存一张图片 首先需要配置GPU内存到300MB左右，默认76MB，配置路径为：Start-&gt;Preferences-&gt;Raspberry Pi Configuration-&gt;Performance-&gt;GPU Memory
ffmpeg -c:v h264_mmal -rtsp_transport tcp -nostdin -loglevel error -i rtsp://username:password@ip -filter:v fps=fps=1/5 test_%03d.jpg 通过 bcmstat 软件观察，cpu消耗一路9%左右，内存消耗也需要60MB，另外需要GPU mem约94MB。
注:使用GPU硬解码两路时，cpu上升到28%左右，内存和gpu内存也等比上升。
结论 使用pi的h264硬件解码时，除GPU额外内存消耗较大外，节省的cpu使用率也很少。当然，目前仅进行了ffmpeg的测试，并未通过其他软件来证实是芯片自生问题还是ffmpeg硬件解码算法问题。建议大家使用ffmpeg解码时，仅进行一路硬解。
参考 Compile FFmpeg for Ubuntu, Debian, or Mint Hardware Encoding with the Raspberry Pi ]]></content></entry><entry><title>Raspberry PI4环境初始化</title><url>/posts/202011/init-pi4/</url><categories/><tags/><content type="html"><![CDATA[pi 4准备 安装最新的pi镜像: 2020-08-20-raspios-buster-armhf 配置apt代理 sudo nano /etc/apt/apt.conf 添加下面语句到文件中：其中如果代理不需要登陆。username:password@可省略；ip和port请按照实际情况填写。
Acquire::http::Proxy &#34;http://username:password@ip:port&#34;; 更新操作系统到最新 sudo apt update sudo apt upgrade 安装bcmstat bcmstat 可以检测到如下指标：
CPU fequencies (ARM, Core, H264, V3D, ISP) Temperature (current and peak) for Core and/or PMIC IRQ/s Network Rx/Tx System utilisation (percentage user, nice, idle etc.) CPU load (including individual cores when available) GPU mem usage RAM usage (with/without swap) Memory leak detection (D/A options - instantaneous and accumulated memory deltas) Undervoltage, ARM frequency cap and temperature throttle event monitoring Customisable columns
安装方式：
curl -Ls https://raw.githubusercontent.com/MilhouseVH/bcmstat/master/bcmstat.sh -o ~/bin/bcmstat.sh chmod +x ~/bin/bcmstat.sh 添加环境变量到.profile，logout再login
export PATH=$PATH:~/bin 添加一个默认配置文件
echo &#34;xgd10&#34; &gt;&gt; ~/.bcmstat.conf 安装golang 下载 go1.15.5.linux-armv6l 执行下面命令：
sudo tar -C /usr/local -xzf go1.15.5.linux-armv6l.tar.gz 添加下面语句到.profile中
export PATH=$PATH:/usr/local/go/bin ]]></content></entry><entry><title>列举pip可安装组件的版本信息</title><url>/posts/202011/pip-list-all-versions-of-package/</url><categories/><tags/><content type="html">方法1 在需要安装组件名称后添加==符号，pip会自动列举可安装版本信息。
输入：
pip3 install pyqt5== 得到：
Could not find a version that satisfies the requirement pyqt5== (from versions: 5.14.0, 5.14.1, 5.14.2, 5.15.0, 5.15.1) 其他方法参考 Python and pip, list all versions of a package that&amp;rsquo;s available</content></entry><entry><title>使用CrowdHuman训练Yolov4</title><url>/posts/202011/use-crowd-human-trainning-yolov4/</url><categories/><tags/><content type="html">本文介绍在agx上使用旷视CrowdHuman库训练yoloV4模型。
数据准备 git clone https://github.com/jkjung-avt/yolov4_crowdhuman cd yolov4_crowdhuman/data ./prepare_data.sh 960x960 在agx上训练 git clone https://github.com/AlexeyAB/darknet.git</content></entry><entry><title>AI库</title><url>/posts/202011/ai-datasets/</url><categories/><tags/><content type="html">旷视人脸，人头,人脸，身体库 CrowdHuman is a benchmark dataset to better evaluate detectors in crowd scenarios. The CrowdHuman dataset is large, rich-annotated and contains high diversity. CrowdHuman contains 15000, 4370 and 5000 images for training, validation, and testing, respectively. There are a total of 470K human instances from train and validation subsets and 23 persons per image, with various kinds of occlusions in the dataset. Each human instance is annotated with a head bounding-box, human visible-region bounding-box and human full-body bounding-box. We hope our dataset will serve as a solid baseline and help promote future research in human detection tasks.
WIDER FACE人脸数据库 WIDER FACE dataset is a face detection benchmark dataset, of which images are selected from the publicly available WIDER dataset. We choose 32,203 images and label 393,703 faces with a high degree of variability in scale, pose and occlusion as depicted in the sample images. WIDER FACE dataset is organized based on 61 event classes. For each event class, we randomly select 40%/10%/50% data as training, validation and testing sets. We adopt the same evaluation metric employed in the PASCAL VOC dataset. Similar to MALF and Caltech datasets, we do not release bounding box ground truth for the test images. Users are required to submit final prediction files, which we shall proceed to evaluate.
kitti KITTI Vision Benchmark Suite .We take advantage of our autonomous driving platform Annieway to develop novel challenging real-world computer vision benchmarks. Our tasks of interest are: stereo, optical flow, visual odometry, 3D object detection and 3D tracking. For this purpose, we equipped a standard station wagon with two high-resolution color and grayscale video cameras. Accurate ground truth is provided by a Velodyne laser scanner and a GPS localization system. Our datsets are captured by driving around the mid-size city of Karlsruhe, in rural areas and on highways. Up to 15 cars and 30 pedestrians are visible per image. Besides providing all data in raw format, we extract benchmarks for each task. For each of our benchmarks, we also provide an evaluation metric and this evaluation website. Preliminary experiments show that methods ranking high on established benchmarks such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias and complement existing benchmarks by providing real-world benchmarks with novel difficulties to the community.
pascal VOC pascal VOC VOC2012: 20 classes. The train/val data has 11,530 images containing 27,450 ROI annotated objects and 6,929 segmentations.Size of segmentation dataset substantially increased. People in action classification dataset are additionally annotated with a reference point on the body.
image-net image-net academictorrents academictorrents 支持对现有开放ai资源库的搜索和基于BitTorrents协议的下载服务的网站。</content></entry><entry><title>人体姿势识别</title><url>/posts/202011/pose-of-person/</url><categories/><tags/><content type="html">本文尝试运行trt_pose项目。
安装依赖 安装PyTorch和Torchvision, 参见 安装Pytorch和Torchvision 安装 torch2trt git clone https://github.com/NVIDIA-AI-IOT/torch2trt cd torch2trt sudo python3 setup.py install --plugins 安装其它依赖 sudo pip3 install tqdm cython pycocotools sudo apt-get install python3-matplotlib 安装trt_pose git clone https://github.com/NVIDIA-AI-IOT/trt_pose cd trt_pose sudo python3 setup.py install 安装jetcam jetcam是一个jetson下操作usb和csi摄像头的库。
jetcam运行依赖模块traitlets，需先安装traitlets。
sudo pip3 install traitlets 然后安装jetcam
git clone https://github.com/NVIDIA-AI-IOT/jetcam cd jetcam sudo python3 setup.py install 运行示例 1import time 2 3t0 = time.time() 4torch.cuda.current_stream().synchronize() 5for i in range(50): 6 y = model_trt(data) 7 8torch.cuda.current_stream().synchronize() 9t1 = time.time() 10 11print(50.0 / (t1 - t0)) 参考 trt_pose</content></entry><entry><title>Hello Jetson Inference</title><url>/posts/202011/hello-jetson-inference/</url><categories/><tags/><content type="html">本文尝试运行Hello AI World,Hello AI World 主要包括：图像分类、物体识别、图像分割。
Jetson nano安装JetPack 略，参见 Jetson Nano环境初始化 编译项目 更新系统，并安装必要的工具
sudo apt update sudo apt upgrade sudo apt install git cmake libpython3-dev python3-numpy clone项目并进行编译，中间会提示下载模型，可以直接点击ok，下载默认的几个模型
git clone --recursive https://github.com/dusty-nv/jetson-inference cd jetson-inference mkdir build cd build cmake ../ make -j$(nproc) sudo make install sudo ldconfig pytorch的安装，参见 安装Pytorch和Torchvision 验证 切换到jetson-inference工程编译目录的bin目录下：
cd jetson-inference/build/aarch64/bin 图像分类 首次运行命令，TensorRT会花费较长时间进行网络优化，优化后的网络文件会缓存在磁盘上，下次运行直接加载优化后的模型。
# C++ ./imagenet images/orange_0.jpg images/test/output_0.jpg # Python ./imagenet.py images/orange_0.jpg images/test/output_0.jpg # C++ ./imagenet images/strawberry_0.jpg images/test/output_1.jpg # Python ./imagenet.py images/strawberry_0.jpg images/test/output_1.jpg 可以使用--network关键字指定使用什么网络，默认未指定系统默认使用googlenet：
# C++ ./imagenet --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg # Python ./imagenet.py --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg # C++ ./imagenet --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg # Python ./imagenet.py --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg 项目支持的完整的模型列表参见： Classifying Images with ImageNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./imagenet rtsp://admin:123456@192.168.1.26 物体识别 首次运行命令，TensorRT会花费较长时间进行网络优化，优化后的网络文件会缓存在磁盘上，下次运行直接加载优化后的模型。
# C++ ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output_peds_0.jpg # Python ./detectnet.py --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output_peds_0.jpg # C++ ./detectnet images/peds_1.jpg images/test/output_peds_1.jpg # Python ./detectnet.py images/peds_1.jpg images/test/output_peds_1.jpg 项目支持的完整的模型列表参见： Locating Objects with DetectNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./detectnet rtsp://admin:123456@192.168.1.26 图像分割 # C++ ./segnet --network=fcn-resnet18-cityscapes images/city_0.jpg images/test/output_city_0.jpg # Python ./segnet.py --network=fcn-resnet18-cityscapes images/city_0.jpg images/test/output_city_0.jpg # C++ ./segnet --network=fcn-resnet18-deepscene images/trail_0.jpg images/test/output_trail_0.jpg # C++ ./segnet --network=fcn-resnet18-deepscene --visualize=mask images/trail_0.jpg images/test/output_mask_trail_0.jpg # C++ ./segnet --network=fcn-resnet18-mhp images/humans_0.jpg images/test/output_humans_0.jpg # Python ./segnet.py --network=fcn-resnet18-mhp images/humans_0.jpg images/test/output_humans_0.jpg 项目支持的完整的模型列表参见： Semantic Segmentation with SegNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./segnet --network=fcn-resnet18-deepscene rtsp://admin:Zyx123456@192.168.1.26 参见 Hello AI World Building the Project from Source Classifying Images with ImageNet Locating Objects with DetectNet Semantic Segmentation with SegNet</content></entry><entry><title>安装Pytorch和Torchvision</title><url>/posts/202011/install-pytorch-torchvision/</url><categories/><tags/><content type="html"><![CDATA[本文简单描述在jetson nano上安装最新的pytorch 1.7.0和torchvision 0.8.1的步骤。
安装 安装前准备 sudo apt update sudo apt upgrade 安装pytorch 首先下载最新的pytorch版本 PyTorch v1.7.0 ，下载后得到文件torch-1.7.0-cp36-cp36m-linux_aarch64.whl.
sudo sudo apt-get install python3-pip libopenblas-base libopenmpi-dev pip3 install Cython pip3 install numpy torch-1.7.0-cp36-cp36m-linux_aarch64.whl 安装torchvision sudo apt-get install libjpeg-dev zlib1g-dev git clone --branch v0.8.1 https://github.com/pytorch/vision torchvision cd torchvision export BUILD_VERSION=0.8.1 sudo python3 setup.py install ## 这步需要编译，时间较长 校验 运行python3
import torch print(torch.__version__) print(&#39;CUDA available: &#39; + str(torch.cuda.is_available())) print(&#39;cuDNN version: &#39; + str(torch.backends.cudnn.version())) a = torch.cuda.FloatTensor(2).zero_() print(&#39;Tensor a = &#39; + str(a)) b = torch.randn(2).cuda() print(&#39;Tensor b = &#39; + str(b)) c = a + b print(&#39;Tensor c = &#39; + str(c)) import torchvision print(torchvision.__version__) python3交互式控制台会输出类似下面的语句：
1.7.0 CUDA available: True cuDNN version: 8000 Tensor a = tensor([0., 0.], device=&#39;cuda:0&#39;) Tensor b = tensor([ 0.3777, -0.5432], device=&#39;cuda:0&#39;) Tensor c = tensor([ 0.3777, -0.5432], device=&#39;cuda:0&#39;) 0.8.0a0+45f960c 参考 pytorch for jetson ]]></content></entry><entry><title>编译最新opencv 4.4.0 with cuda</title><url>/posts/202011/build-opencv-with-cuda/</url><categories/><tags/><content type="html">本文介绍如何在nano/agx上编译opencv 4.4.0 with cuda.
步骤 该库在原有库基础上做了一些调整，原有库在nano上只能单线程运行。需要原有库的同学参见参考连接。
# clone the repository git clone https://github.com/peace0phmind/nano_build_opencv.git cd nano_build_opencv ./build_opencv.sh 参考 nano_build_opencv</content></entry><entry><title>Ubuntu使用Mac键盘</title><url>/posts/202011/ubuntu-use-mac-keyboard/</url><categories/><tags/><content type="html">介绍如何在ubuntu下使用mac键盘。
由于长期使用mac的缘故，对command按键的使用非常顺手，又由于需要使用blender软件，所以购买了Keychron K4的带数字键的机械硬盘，后来发现这个键盘虽然可以完成blender中的一些视图切换，但在截屏方面非常不方便（没有Print Screen按键）,建议有和我同样诉求的购买全尺寸键盘。
打开settings的界面，在Region &amp;amp; Language中找到Input Sources，点击下面的+号，在出现的列表中选择English(Macintosh)。
具体可以参考下面参考章节中的图片，但不要选择图片中的输入方式，图片中的输入方式会导致Shift + 3的组合键输出的是£而不是期望的#。
参考： Using a UK mac keyboard on Ubuntu</content></entry><entry><title>Blender 2.8x快捷键</title><url>/posts/202011/blender-2.8x-shortcuts/</url><categories/><tags/><content type="html">本文主要记录 Blender 2.8x的快捷方式。
注：num_做前缀的按钮表示数字键盘区的按键，num_7表示的是数字小键盘7，其他对照类比。普通的按键7会直接用7标识。lmb表示鼠标左键，rmb表示鼠标右键，mmb表示鼠标中键。
设置单位 blender 2.82默认单位为m,需要设置为mm, Unit Scale需要甚至为0.001.
通用快捷键 shift-a show add menu(添加三维物体) shift-s-1 cursor to world origin（鼠标到世界原点） shift-s-2 cursor to selected（鼠标到选择点，物体的中心点） shift-s-3 cursor to active（鼠标到活动点） shift-s-4 cursor to gride（鼠标到网格） shift-s-6 selection to grid shift-s-7 selection to cursor (keep offset) shift-s-8 selection to cursor shift-s-9 selection to active x-d remove object（删除物体等） ctrl-lmb Lasso select: drag the mouse to form a freehand selection area.(选择物体等) 视角切换 num_7 Top View ctrl-num_7 Bottom View num_1 Front View ctrl-num_1 Back View num_3 Right View ctrl-num_3 Left View num_0 Camera View num_. Put select objects to the view center.(select object, move mouse to view, press num_. button)（将选择的所有物体放在视图正中间，有别于shift-c） shift-mmb move view 对象模式（已选择物体） tab Start/stop EditMode. alt-e. Start/stop EditMode. Alternative hotkey: tab. s size(scale) mode r rotate mode a select all aa deselect all home see all object in one view shift-c CentreZero View. The 3DCursor is set to zero (0,0,0) and the view is changed so that all Objects, including the 3Dcursor, can be displayed. This is an alternative for home.（将所有物体，包括的灯光和摄像头等都放置到视图正中间，并设置3d鼠标到原点） shift-d. Add Duplicate. The selected Objects are duplicated. Grab mode starts immediately thereafter. alt-g. Clears translations, given in Grab mode. The X,Y,Z locations of selected Objects are set to zero. alt-j. Join faces, selected triangular faces are joined in pairs and transformed to quads z-4 wireframe mode（线框模式） z-6 solid mode z-8 rendered mode z-2 material preview shift-z toggles shaded mode on/off(在线框和投影模式下切换) alt-z toggles textured mode on/off（在线框和纹理模式下切换） alt-s Clears size. The X,Y,Z dimensions of selected Objects are set to 1.0. ctrl-m mirror menu. alt-o Clear Origin. The ‘Origin’ is erased for all Child Objects, which causes the Child Objects to move to the exact location of the Parent Objects. m Moves selected Object(s) to another layer, a pop-up appers. g Grab Mode. g-x g-y g-z constrains movement to X, Y or Z axis of the global reference. 编辑模式（mesh） e extrude selected e-x e-y e-z constrains extrude selected to X, Y or Z axis of the global reference. a select all a-a deselect all alt-lmb select a collection of points f Make Edge/Face. If 2 vertices are selected, an edge is created. If 3 or 4 vertices are selected, a face is created. shift-f Fill selected. All selected vertices that are bound by edges and form a closed polygon are filled with triangular faces. Holes are automatically taken into account. This operation is 2D; various layers of polygons must be filled in succession. alt-f Beauty Fill. The edges of all the selected triangular faces are switched in such a way that equally sized faces are formed. This operation is 2D; various layers of polygons must be filled in succession. The Beauty Fill can be performed immediately after a Fill. ctrl-f Flip faces, selected triangular faces are paired and common edge of each pair swapped. ctrl-r Face Loop Cut.Face loops are highlighted starting from edge under mouse pointer. alt-m select multiple points and merge them shift-c CentreZero View. The 3DCursor is set to zero (0,0,0) and the view is changed so that all Objects, including the 3Dcursor, can be displayed. This is an alternative for home. o Switch in/out of Proportional Editing. shift-g Select Similar ctrl-e edge menu.(include bridge edge loops)(对数量相等的两条边进行自动全连接) shift-n and shift-ctrl-n recalculate the normals of selected faces(重新计算法线) ctrl-b bevel tool 参考 Blender HotKeys In-depth Reference blender-2-8-where-is-the-remove-doubles blender-2-8-for-architecture</content></entry><entry><title>常用命令与工具</title><url>/posts/202010/usage-commands/</url><categories/><tags/><content type="html">类似mac airdrop的工具 这里强烈推荐一个类似mac下airdrop的网站, https://snapdrop.net 这个网站可以让使用同一局域网的所有设备（jetson agx/nano, raspberry pi, windows, linux_x86, phone etc.）相互快速共享文件或发送消息。(使用时请关闭代理，否则无法正确找到对方)
用浏览器打开即可看到自己的名字，每次刷新名字随机产生。点击对方头像可以选择文件，拖动文件到头像也可以进行文件分享。在头像上点击右键，弹出框中输入需要发送的消息。
还有个 https://www.sharedrop.io ，不过这个网站用的缓存服务器需要代理才可以访问，不是很方便。
清除DNS缓存 ubuntu操作系统使用如下命令：
sudo systemd-resolve --flush-caches 22.04 resolvectl flush-caches 参考： How to clear DNS cache 获取不同网络环境下的ping值，DNS解析结果等 https://www.boce.com</content></entry><entry><title>调整内存使用</title><url>/posts/202010/tuning-memory-usage/</url><categories/><tags/><content type="html">nano分4G版和2G版。其SD镜像分别为： 4G版 ， 2G版 。
4G和2G内存版本的主要区别在于启动后的桌面，2G内存版考虑到内存少的情况，启用的是LXDE的桌面。（切换到level 3后, 4G版镜像比2G版镜像多0.1G，jtop观察前者0.4G,后者0.3G）
禁用桌面GUI 考虑到nano的内存紧缺，如果不是直接在nano上进行GUI开发调试，那么会考虑使用level 3的方式启动nano。禁用桌面可以节省(Unity/GNOME 大概 800MB, LXDE可以节省大概250MB）内存。
禁用桌面
sudo init 3 启用桌面
sudo init 5 如果希望修改系统默认启动行为，则输入如下命令：
默认启动到控制台界面(level 3)：
sudo systemctl set-default multi-user.target 默认启动到图形界面(level 5):
sudo systemctl set-default graphical.target 创建swap文件(可选) 2G版本nano在启动配置时可以选择添加swap，也可以使用jtop工具通过界面配置swap文件的启用和大小。
此处给出手动创建和启用swap文件的方法： 假设需要创建4GB swap文件：
sudo fallocate -l 4G /mnt/4GB.swap sudo mkswap /mnt/4GB.swap sudo swapon /mnt/4GB.swap 将下面行添加到/etc/fstab文件中
/mnt/4GB.swap none swap sw 0 0 创建swap分区(可选) 通过disks工具在磁盘上创建一个单独的分区，假设新建分区/dev/sda1
sudo mkswap /dev/sda1 # get the new partition id: xxx-xxx-xxx sudo blkid /dev/sda1 # write config to file echo &amp;#34;xxx-xxx-xxx none swap sw 0 0&amp;#34; | sudo tee -a /etc/fstab 重新启动操作系统。
参考 How to Add a Swap Partition on Jetson TX1 How do I add swap after system installation?</content></entry><entry><title>Jetson Nano环境初始化</title><url>/posts/202010/nano-env-init/</url><categories/><tags/><content type="html"><![CDATA[本文主要介绍Jetson Nano启动后环境的准备工作. TF卡flush以及系统启动初始化 下载并烧录最新的TF卡镜像 4G内存版 ; 2G内存版 。完成nvidia的一系列初始化操作（协议，时区配置，账号信息配置等）。
Ubuntu 系统的更新 sudo apt update sudo apt upgrade sudo apt dist-upgrade sudo apt autoremove 安装ohmyzsh 个人比较喜欢ohmyzsh下的一些快捷输入和操作方式。 由于墙的存在，直接安装会失败，可以手动安装
首先需要安装zsh
sudo apt install zsh -y 手动安装ohmyzsh
# Clone the repository git clone https://github.com/ohmyzsh/ohmyzsh.git ~/.oh-my-zsh # Optionally, backup your existing ~/.zshrc file cp ~/.zshrc ~/.zshrc.orig # Create a new zsh configuration file cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc # Change your default shell chsh -s $(which zsh) 安装ohmyzsh的zsh-autosuggestions插件 zsh-autosuggestions插件支持超棒的历史命令联想功能。
# Clone this repository into $ZSH_CUSTOM/plugins (by default ~/.oh-my-zsh/custom/plugins) git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions # Add the plugin to the list of plugins for Oh My Zsh to load (inside ~/.zshrc): plugins=(zsh-autosuggestions) # Start a new terminal session. 安装jdk sudo apt install openjdk-8-jdk -y 安装terminator terminator是ubuntu下比较美观，且支持分屏的工具。其可以类比为mac下的iterm2。
sudo apt install terminator -y 安装pip3 sudo apt install python3-pip -y 安装jtop jtop可以用来显示系统资源使用情况，比如：查看cpu，内存，gpu使用情况；查看安装的库的信息；控制风扇启用和转速等。
sudo -H pip3 install -U jetson-stats sudo systemctl restart jetson_stats.service 使用前还需要logout或者reboot
使用jtop启用jetson_clocks 在不启用jetson_clocks时，jetson的cpu和gpu的主频是根据需要动态变化的，且如果支持PWM的风扇默认也是不工作的（Fan转速为0，如果是普通的3pin风扇则会持续稳定运行。只有4pin的调速风扇会受到jetson_clocks的影响控制转速）。建议启用jetson_clocks，将主频固定下来。在GUI界面，未启用jetson_clocks时会有卡顿的现象。
输入jtop启动jtop，按5进入控制界面：
点击system按钮，启用Fan转速的Auto模式 点击jetson_clocks左边的s按钮，启动jetson_clocks 点击boot左边的e，设置jetson_clocks系统启动自动运行 安装golang环境 从 golang下载页面 下载最新的 go1.15.3.linux-arm64安装包 执行下面命令安装golang到/usr/local目录下:
sudo tar -C /usr/local -xzf go1.15.3.linux-arm64.tar.gz 将/usr/local/go/bin目录添加到PATH环境变量，参见
export PATH=$PATH:/usr/local/go/bin:$HOME/go/bin 安装curl curl 支持 http, https, socks4, socks5 代理 wget 支持 http, https 代理
而socks5支持dns代理，可以解决一些dns污染的问题
sudo apt install curl -y 配置nvcc环境变量 拷贝下面代码到.bashrc或.zshrc文件(如果你安装使用了zsh)，或者.profile或.zprofile文件。 关于 .*rc和.*profile文件的使用说明参见 export PATH=/usr/local/cuda/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH 配置docker权限 创建 docker 组(可选，nano中已包含docker组) 将当前用户添加到 docker 组中 激活组变化 sudo groupadd docker sudo usermod -aG docker $USER newgrp docker 当激活了组变化后，执行docker ps 可以看到docker命令正确执行。
配置docker registry mirrors 配置docker registry mirrors可以进行docker pull加速，解决docker pull缓慢的问题。
使用编辑器打开/etc/docker/daemon.json文件，按json格式添加如下内容：
&#34;registry-mirrors&#34;: [&#34;https://registry.docker-cn.com&#34;] 此处url也可使用阿里云的个人docker加速器，例如：https://xxxxx.mirror.aliyuncs.com，这里 xxxx参见 添加完后，daemon.json文件内容类似如下：
{ &#34;runtimes&#34;: { &#34;nvidia&#34;: { &#34;path&#34;: &#34;nvidia-container-runtime&#34;, &#34;runtimeArgs&#34;: [] } }, &#34;registry-mirrors&#34;: [&#34;https://7s7m9b11.mirror.aliyuncs.com&#34;] } 安装 docker-compose sudo apt install docker-compose -y 安装右键resize image工具 sudo apt install nautilus-image-converter 上面命令安装完成后，执行下面命令重启nautilus
nautilus -q ]]></content></entry><entry><title>AGX添加nvme ssd并设置从ssd启动</title><url>/posts/202010/add-nvme-ssd/</url><categories/><tags/><content type="html">AGX出厂自带32G EMMC，并自带Ubuntu 18.04 + JetPack 4.4。本文对EMMC进行了磁盘读写的测试，并且对AGX进行改装，分别测试加装了海康的1T nvme ssd硬盘和SAMSUNG 1T nvme ssd，并进行了对比测试。最后简单介绍了了如何将AGX的默认启动方式修改为从nvme的ssd启动。
磁盘读写性能测试方式 使用linux下的dd进行磁盘读写性能测试。
测试磁盘写速度 sync; dd if=/dev/zero of=tempfile bs=1M count=1024; sync 测试磁盘读速度 dd if=tempfile of=/dev/null bs=1M count=1024 清理读缓存 sudo /sbin/sysctl -w vm.drop_caches=3 emmc性能测试 emmc写盘和覆盖写 emmc写盘1.4 GB/s(实际测试结果输出后，该民令并没有立即结束，所以这里的数据并不能用于参考) emmc覆盖写的速度大概在119 MB/s emmc缓存读和直接读的速度 emmc缓存读的速度很高，在7.7GB/s左右 emmc直接读取的速度很低，在307 MB/s左右 SamSung 1T SSD性能测试 SamSung写盘和覆盖写 SamSung写盘1.3 GB/s SamSung覆盖写的速度大概在897 MB/s SamSung缓存读和直接读的速度 SamSung缓存读的速度很高，在7.1GB/s左右 SamSung直接读取的速度很低，在1.7 GB/s左右 HikVision 1T SSD性能测试 HikVision写盘和覆盖写 HikVision写盘1.3 GB/s HikVision覆盖写的速度大概在992 MB/s HikVision缓存读和直接读的速度 HikVision缓存读的速度很高，在7.9GB/s左右 1.HikVision直接读取的速度很低，在1.6 GB/s左右 对比 HikVision 1T和SamSung 1T的性能相近，价格前者8百不到，后者1200左右，相差400左右，我先买了HikVision后购买并替换为了SamSung的ssd，下面介绍下原因：
先看下两个ssd的照片对比，上面为HikVison，下面为SamSung：
正面对比，差别不大 背面对比：从背面看SamSung的背面没有元器件，Hikision的有很多细小密集的元器件。 从HikVision装配图来看,背面有元器件会导致整个ssd中间突起。 替换下来的HikVision，已经有轻微变形了。 从SamSung装配图来看,背面没有元器件会非常贴合Agx的PCI-E接口。 修改启动盘，从ssd启动 完成物理装配后开机 在Disks工具中找到1T SSD，点击小齿轮，对整个磁盘进行format创建一个大分区（有别于参考中，还要预留16G空间，此处使用完整空间）。完成format后，保持磁盘在unmount状态。 打开命令行，执行下面命令：（注： 在我的disks中，我的磁盘名称为/dev/nvme0n1，而不是参考中的/dev/nvme0n1p1，可能与我使用的jetpack 4.4.1有关，所以我修改了代码以保证程序可以运行） # clone the repository: git clone https://github.com/peace0phmind/rootOnNVMe.git # switch to that repository&amp;#39;s directory cd rootOnNVMe # copy the rootfs of the eMMC card to the SSD ./copy-rootfs-ssd.sh # Finally, we will add a service which will run a script when the system starts up. ./setup-service.sh 参考 Install NVMe SSD on NVIDIA Jetson AGX Developer Kit Jetson Xavier NX – Run from SSD</content></entry><entry><title>Agx开箱</title><url>/posts/202010/get-and-assemble-agx/</url><categories/><tags/><content type="html">经过20天漫长的等待，终于在某个星期日收到了包裹。
包裹看上去挺大的。 拆开后AGX的盒子大概这么大，图的上方是我的Mac book pro,可以对比参考下大小。 打开盒子，AGX实际只有盒子大小的1/4，就只中间一块，保护的很好。 AGX的实际大小差不多是一个PCI-E插槽的大小。 电源插头不是国标的，毕竟是海外购，能够理解，自己的家里找了个电源线插上，没有的话可以上某宝购买，几块钱还包邮。 接上显示器，键盘鼠标等设备，开机即可进入系统（中间License选择界面和初始化配置界面按提示操作）。（AGX内置了一块32G的eMMC,默认预装Ubuntu 18.04） 由于AGX接口太少(一个HDMI， 2个type-c，一个E-SATA接口，一个micro-usb)，所以测试了一下外接华为扩展坞，支持双屏显示，扩展网口等。上图我插上了USB的键盘和无线鼠标。</content></entry><entry><title>开篇</title><url>/posts/202010/my-first-post/</url><categories/><tags/><content type="html">9月份某个星期六，加班到恨晚考虑到第二天还要到公司，于是将电脑放在了窗边的工位上。第二天一场大雨把我2013年下半年购买的顶配（习惯购买默认出厂顶配，非定制机型）Mac Book Pro泡在了水里。屏幕被烧坏，但机器加电连接外接显示器依然可以正常工作，不得不佩服苹果的做工扎实。吃饭的家伙没有了，得赶紧整一个，否则耽误项目进度，于是有了下面的折腾之旅。
按理说我是标准的“Apple Fans”，电脑坏了会第一时间考虑购买苹果的最新款顶配Mac Book Pro，那我为啥还要折腾呢？
我的Mac Book Pro是最后一代采用nvidia显卡的苹果笔记本，可以说是绝版nvidia+apple的配置，后面的mac book电脑都无法跑cuda，当年在自己的笔记本上给小伙伴演示使用cuda加速tf，而其他人都只能跑在linux系统上，这种独特的感觉在在现在的苹果电脑上找不到了。 作为一个优秀的打字员，学会的第一个技能就是盲打（不看键盘打字），紧接着的第二个技能就是熟记大部分常用软件的快捷键，第三个技能就是手速快，配合上快捷键，那屏幕上翻飞的窗口，别人看了就是一种艺术的享受。自从mac有了bar&amp;hellip;，关键bar还替换了常用的一些F1-12，切换不同窗口上下文得看到bar变化后再去点击&amp;hellip;。可以说bar就不是为我等优秀打字员设计的。对于熟记快捷键的我来说，bar就是一个摆设，为没用的东西花上3000快，不值！！！ 苹果我只崇拜2个人，Jobs于2011年10月去世了；苹果首席设计师乔纳森·艾维（Jony Ive）从Jobs去世的那年开始就风闻计划离开苹果，终于在去年某天离开了苹果。从2012年到现在，苹果除了换换配置，更新更新周边，系统升级下皮肤，几乎就没有以前那种令人惊艳的创新的产品面试（那个bar真不算，那个是设计上的倒退，对于我来说；也有人说窄边框，但窄边框真不是苹果首先搞出来的）。缺少了这两位的苹果，已经从一个伟大的公司变成了一个只考虑如何赚钱的，搞办公室文化的体量很大的公司。可以说，2013年前，还有很多技术是苹果首次采用和创新的，之后就真的没有什么能够吸引我注意的产品了。 随着虚拟化，k8s等技术得到极大的运用，作为优秀打字员的我也希望在本地好好玩玩这些技术，所以我需要一个32-64G内存，1T硬盘的笔记本，可惜我苹果顶配只有16G内存。7年了，16G内存还是16G内存，没有发生过变化。有人有不同观点，说32G内存普通人用不上；其实我想说，最用不上的更新是CPU，我就打打字，你说CPU能有多少占用？还每年百分之多少提升，给我打字员用就是浪费。如今的Raspberry Pi 3B都够用（当然排除喝咖啡时间，当然现在技术都先进了，都在云端和咖啡了，及其CPU也就本地喝咖啡用用，没啥强烈诉求了）。按照摩尔定律6年了，内存少说应该上到64G而且价格不变，考虑到用户用不上这么多内存，配置32G内存的电脑价格应该还要有下降。看看苹果定制机型，32G版本的配置足够我买其它品牌相同配置的2个。 介于苹果已经走下神坛；介于库克把我崇拜的Ive排挤出了公司；介于苹果没有创新的点吸引到我花多一倍的钱购买，苹果的选项被我划掉了。
市面上标配32G内存的电脑真的太少，太贵了。出厂默认32G内存的笔记本电脑型号很少，且其16G机型和32G机型相差很多，有些小伙伴都是买16G机型自己回来自己加上一个16G的。这个选项我也考虑过，但是没有选到好看的机器（可以自己加内存的笔记本，都比较厚重&amp;hellip;），所以这个只是待选项，继续寻找中。
在上Nvidia网站找东西的时候，无意间发现我关注的Jetson AGX出32G版本的了(记得刚出来的时候是16G的把，当时Mac正常工作，没有考虑过，所以可能记错了)，一个想法跃然脑中，使用AGX作开发电脑！！！
在对比了某宝价格和amazon海外购，决定在amazon上进行海外购，给国家多贡献点自己的力量。
于是果断出手购买了一个Huawei 16G的最新笔记本先用着。才4K多的价格，相对于类似配置的苹果来说，那真的是白菜价了。
下面，即将开启AGX折腾之旅。</content></entry></search>