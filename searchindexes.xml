<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Machine Learning</title><url>/posts/202211/01-machine-learning/</url><categories><category>machine-learning</category></categories><tags><tag/></tags><content type="html"> # ML ## Suppervised Learning - Training Data - Labels - Gradient Descent ## Self-Supervised Learning - Pre-Trained Model(Foundation Model) - unlabeled Data - Downstream Tasks - Models - BERT - ELMo - GPT-2 - GPT-3 - T5 ## Generative Adversarial Network - 收集大量x和y - x和y是unpaired - 研究成果 - [Unsupervised Abstractive Summarization](https://arxiv.org/abs/1810.02851) - [Unsupervised Translation](https://arxiv.org/abs/1710.11041) - [04087](https://arxiv.org/abs/1710.04087) - [Unsupervised ASR](https://arxiv.org/abs/2105.11084) - [1804.00316](https://arxiv.org/abs/1804.00316) - [1812.09323](https://arxiv.org/abs/1812.09323) - [1904.04100](https://arxiv.org/abs/1904.04100) ## Reinforcement Learning (RL) ## Anomaly Detaction(异常检测, 让机器知道它不知道) ## Explainable AI ## Model Attack (模型攻击) ## Domain Adaptation ## Network Compression ## Life-Long Learning ## Meta Learning = Learn to Learn - Few-shot Learning Machine Learning是什么 简单的理解就是在输入和输出中找一个函数
参考 系列文档是国立台湾大学 李宏毅 老师Machine Learning系列教材的学习整理。
Machine Learning 2022 Machine Learning 2021 Machine Learning 2020 Machine Learning 2019 Machine Learning 2016 ALL</content></entry><entry><title>有用的公式</title><url>/posts/202211/usable-formula/</url><categories><category>blog</category></categories><tags><tag>formula</tag></tags><content type="html"><![CDATA[Use $\Sigma$ in different mode sum mode making-the-subscript-under-the-summation use color Using_colours_in_LaTeX inline math $\sum_{i=1}^{\infty}|x_i-y_i|$ $\sum_{i=1}^{\infty}|x_i-y_i|$
display math $$ \sum_{i=1}^{\infty}|x_i-y_i| $$ $$ \sum_{i=1}^{\infty}|x_i-y_i| $$
use \limits $\sum\limits_{i=1}^{\infty}|x_i-y_i|$ $\sum\limits_{i=1}^{\infty}|x_i-y_i|$
use color ${\color{red}\eta}\frac{{\delta}L}{{\delta}W}|_{w=w^0}$ ${\color{red}\eta}\frac{{\delta}L}{{\delta}W}|_{w=w^0}$
newline, space, align and tag new line use \cr or \\\\ space use \\,, \quad align use \begin{align}, \end{align} and &amp; tag use \tag{1}, or use ams automatic , equation-numbers tag with ams automatic, will omit by \notag or block symbol end with *, for example: \begin{align*}, \end{align*} use \begin{align} and \end{align} instead of $$ or $ \begin{align} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\\\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\\,b\tag{xyz} \end{align} \begin{align} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\,b\tag{xyz} \end{align}
\begin{align*} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\\\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\\,b\tag{xyz} \end{align*} \begin{align*} x&amp;=y &amp; w &amp;=z &amp; a&amp;=b+c \\ 2x&amp;=-y &amp; 3w&amp;=\frac{1}{2}z &amp; a&amp;=b \notag \cr -4 + 5x&amp;=2+y &amp; w+2&amp;=-1+w &amp; a \quad b&amp;=c\,b\tag{xyz} \end{align*}
block symbol: equation, split, multline, gather, align equation equation can only include one equation or it will not render \begin{equation} x=y \end{equation} \begin{equation} x=y \end{equation}
\begin{equation} x=y \cr y=b \end{equation} \begin{equation} x=y \cr y=b \end{equation}
split split can use with equation but the tag was only one \begin{equation} \begin{split} x=y \cr y=b \end{split} \end{equation} \begin{equation} \begin{split} x=y \cr y=b \end{split} \end{equation}
multline multline same as equation with split but with different align \begin{multline} x=y \cr y=b \end{multline} \begin{multline} x=y \cr y=b \end{multline}
gather \begin{gather} x=y \cr y=b \end{gather} \begin{gather} x=y \cr y=b \end{gather}
align \begin{align} x=y \cr y=b \end{align} \begin{align} x=y \cr y=b \end{align}
matrices Matrices Type Latex markup Render as Plain \begin{matrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{matrix} \begin{matrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{matrix} Parentheses; round brackets \begin{pmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{pmatrix} \begin{pmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{pmatrix} Brackets; square brackets \begin{bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{bmatrix} \begin{bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{bmatrix} Braces; curly brackets \begin{Bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Bmatrix} \begin{Bmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Bmatrix} Pipes \begin{vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{vmatrix} \begin{vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{vmatrix} Double pipes \begin{Vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Vmatrix} \begin{Vmatrix} 1 &amp; 2 &amp; 3\cr a &amp; b &amp; c \end{Vmatrix} 参考 Classical ML Equations in LaTeX ]]></content></entry><entry><title>有用的符号</title><url>/posts/202211/usable-symbols.html</url><categories><category>blog</category></categories><tags><tag>mathjax</tag><tag>symbol</tag></tags><content type="html"><![CDATA[参考 MathJax LaTex Ref LaTex Math Symbols LaTex Math Symbols LaTeX_mathematical_symbols 空格符号 Regular space : There&#39;s a regular&amp;nbsp;space. Two spaces gap : There&#39;s a regular&amp;ensp;space. Four spaces gap: There&#39;s a regular&amp;emsp;space. There&rsquo;s a regular space. There&rsquo;s a regular space. There&rsquo;s a regular space. Math Mode Accents $\hat{a}$ \hat{a} $\check{a}$ \check{a} $\tilde{a}$ \tilde{a} $\acute{a}$ \acute{a} $\grave{a}$ \grave{a} $\dot{a}$ \dot{a} $\ddot{a}$ \ddot{a} $\breve{a}$ \breve{a} $\bar{a}$ \bar{a} $\vec{a}$ \vec{a} $\widehat{A}$ \widehat{A} $\widetilde{A}$ \widetilde{A} Greek Letters alpha, beta, gamma, delta, epsilon, zeta, eta, theta, iota, kappa, lambda, mu, nu, xi, omicron, pi, rho, sigma, tau, upsilon, phi, chi, psi, omega.
$\alpha$ \alpha $\beta$ \beta $\Gamma$ $\gamma$ \Gamma \gamma $\Delta$ $\delta$ \Delta \delta $\epsilon$ $\varepsilon$ \epsilon \varepsilon $\zeta$ \zeta $\eta$ \eta $\Theta$ $\theta$ $\vartheta$ \Theta \theta \vartheta $\iota$ \iota $\kappa$ \kappa $\Lambda$ $\lambda$ \Lambda \lambda $\mu$ \mu $\nu$ \nu $\Xi$ $\xi$ \Xi \xi $o$ o (omicron) $\Pi$ $\pi$ $\varpi$ \Pi \pi \varpi $\rho$ $\varrho$ \rho \varrho $\Sigma$ $\sigma$ $\varsigma$ \Sigma \sigma \varsigma $\tau$ \tau $\Upsilon$ $\upsilon$ \Upsilon \upsilon $\Phi$ $\phi$ $\varphi$ \Phi \phi \varphi $\chi$ \chi $\Psi$ $\psi$ \Psi \psi $\Omega$ $\omega$ \Omega \omega Arrows $\leftarrow$ \leftarrow or \gets $\rightarrow$ \rightarrow or \to $\leftrightarrow$ \leftrightarrow $\Leftarrow$ \Leftarrow $\Rightarrow$ \Rightarrow $\Leftrightarrow$ \Leftrightarrow $\longleftarrow$ \longleftarrow $\longrightarrow$ \longrightarrow $\longleftrightarrow$ \longleftrightarrow $\Longleftarrow$ \Longleftarrow $\Longrightarrow$ \Longrightarrow $\Longleftrightarrow$ \Longleftrightarrow or \iff $\uparrow$ \uparrow $\downarrow$ \downarrow $\updownarrow$ \updownarrow $\Uparrow$ \Uparrow $\Downarrow$ \Downarrow $\Updownarrow$ \Updownarrow $\mapsto$ \mapsto $\longmapsto$ \longmapsto $\multimap$ \multimap $\hookleftarrow$ \hookleftarrow $\hookrightarrow$ \hookrightarrow $\upharpoonleft$ \upharpoonleft $\leftharpoonup$ \leftharpoonup $\rightharpoonup$ \rightharpoonup $\upharpoonright$ \upharpoonright $\leftharpoondown$ \leftharpoondown $\rightharpoondown$ \rightharpoondown $\downharpoonleft$ \downharpoonleft $\leftrightharpoons$ \leftrightharpoons $\rightleftharpoons$ \rightleftharpoons $\downharpoonright$ \downharpoonright $\leftleftarrows$ \leftleftarrows $\rightrightarrows$ \rightrightarrows $\upuparrows$ \upuparrows $\leftrightarrows$ \leftrightarrows $\rightleftarrows$ \rightleftarrows $\downdownarrows$ \downdownarrows $\dashleftarrow$ \dashleftarrow $\dashrightarrow$ \dashrightarrow $\nearrow$ \nearrow $\twoheadleftarrow$ \twoheadleftarrow $\twoheadrightarrow$ \twoheadrightarrow $\searrow$ \searrow $\leftarrowtail$ \leftarrowtail $\rightarrowtail$ \rightarrowtail $\swarrow$ \swarrow $\Lsh$ \Lsh $\Rsh$ \Rsh $\nwarrow$ \nwarrow $\Lleftarrow$ \Lleftarrow $\Rrightarrow$ \Rrightarrow $\rightsquigarrow$ \rightsquigarrow or \leadsto $\looparrowleft$ \looparrowleft $\looparrowright$ \looparrowright $\leftrightsquigarrow$ \leftrightsquigarrow $\curvearrowleft$ \curvearrowleft $\curvearrowright$ \curvearrowright $\circlearrowleft$ \circlearrowleft $\circlearrowright$ \circlearrowright Miscellaneous Symbols $\dots$ \dots $\cdots$ \cdots $\vdots$ \vdots $\ddots$ \ddots $\hbar$ \hbar $\imath$ \imath $\jmath$ \jmath $\ell$ \ell $\Re$ \Re $\Im$ \Im $\aleph$ \aleph $\wp$ \wp $\forall$ \forall $\exists$ \exists $\mho$ \mho $\partial$ \partial $&rsquo;$ ' $\prime$ \prime $\emptyset$ \emptyset $\infty$ \infty $\nabla$ \nabla $\triangle$ \triangle $\Box$ \Box $\Diamond$ \Diamond $\bot$ \bot $\top$ \top $\angle$ \angle $\surd$ \surd $\diamondsuit$ \diamondsuit $\heartsuit$ \heartsuit $\clubsuit$ \clubsuit $\spadesuit$ \spadesuit $\neg$ \neg or \lnot $\flat$ \flat $\natural$ \natural $\sharp$ \sharp ]]></content></entry><entry><title>Mpv常用配置</title><url>/posts/202211/mpv-config/</url><categories><category>blog</category></categories><tags><tag>mpv</tag></tags><content type="html"><![CDATA[配置文件位置 系统范围的配置文件&rsquo;mpv.conf&rsquo;位于您的配置目录中（例如 /etc/mpv 或 /usr/local/etc/mpv）。 用户特定的文件是~/.config/mpv/mpv.conf。 有关详细信息和平台细节（特别是 Windows 路径），请参阅文件部分。
用户特定的选项会覆盖系统范围的选项，而命令行上给出的选项也会覆盖。配置文件的语法是 option=value。 #之后的所有内容都被视为注释。可以通过将它们设置为 yes 来启用没有值的选项，并通过将它们设置为 no 来禁用它们。
Screenshot常用配置 screenshot-format=&#34;jpg&#34; screenshot-template=&#34;%F%n&#34; screenshot-directory=&#34;~/Pictures/mpv-shot&#34; screenshot-jpeg-quality=70 screenshot-png-compression=9 screenshot-format 设置用于保存屏幕截图的图像文件类型。png, jpg(default), jpeg, webp, jxl
screenshot-template 指定用于保存屏幕截图的文件名模板。模板指定没有文件扩展名的文件名，并且可以包含格式说明符，在截屏时将被替换。 默认情况下，模板是 mpv-shot%n，这会产生像mpv-shot0012.png这样的文件名。
模板可以以相对或绝对路径开头，以指定应保存屏幕截图的目录位置。
如果最终的屏幕截图文件名指向一个已经存在的文件，则该文件不会被覆盖。屏幕截图将不会被保存，或者如果模板包含%n，则使用不同的新生成的文件名保存。
%[#][0X]n 一个序列号，用零填充到长度X（默认值：04）。例如。传递格式%04n将在第12个屏幕截图中产生0012。 每次截取屏幕截图或文件已存在时，该数字都会增加。长度X必须在0-9范围内。使用可选的#符号，mpv将使用最低的可用编号。 例如，如果您截取三张截图——0001、0002、0003——并删除前两张，那么接下来的两张截图将不再是0004和0005，而是再次成为0001和0002。
%f 当前播放视频的文件名。
%F 与 %f 相同，但去掉文件扩展名，包括点。
%x 当前播放视频的目录路径。如果视频不在文件系统上（但例如 http://），则扩展为空字符串。
%X{fallback} 与 %x 相同，但如果视频文件不在文件系统上，则返回 {&hellip;} 内的后备字符串。
%p 当前播放时间，与 OSD 中使用的格式相同。结果是“HH:MM:SS”形式的字符串。例如，如果视频的时间位置为 5 分 34 秒，则 %p 将替换为“00:05:34”。
%P 与 %p 类似，但以毫秒为单位延长播放时间。它的格式为“HH:MM:SS.mmm”，其中“mmm”是播放时间的毫秒部分。
%wX 使用格式字符串 X 指定当前播放时间。%p 类似于 %wH:%wM:%wS，%P 类似于 %wH:%wM:%wS.%wT。
有效的格式说明符:
%wH 小时（用 0 填充到两位数） %wh 小时（无填充） %wM 分钟 (00-59) %wm 总分钟数（包括小时数，与 %wM 不同） %wS 秒 (00-59) %ws 总秒数（包括小时和分钟） %wf 像 %ws，但返回的是浮点数 %wT 毫秒 (000-999) %tX 使用格式X指定当前本地日期/时间。此格式说明符在内部使用 UNIX strftime() 函数，并将传递“%X”的结果插入 strftime。 例如，%tm 将插入当前月份的数字作为数字。您必须使用多个 %tX 说明符来构建完整的日期/时间字符串。
%{prop[:fallback text]} 插入输入属性“prop”的值。例如。 %{filename} 与 %f 相同。如果该属性不存在或不可用，则插入错误文本，除非指定了回退。
%% 替换为 % 字符本身。
screenshot-directory 将屏幕截图存储在此目录中。此路径与&ndash;screenshot-template生成的文件名相连。如果模板文件名已经是绝对的，则忽略该目录。
如果该目录不存在，则在第一个屏幕截图中创建该目录。如果不是目录，尝试写截图时会报错。
默认情况下未设置此选项，因此会将屏幕截图写入启动 mpv 的目录。在伪 gui 模式下, 它被设置为桌面。
screenshot-png-compression=&lt;0-9&gt; 设置PNG压缩级别。更高意味着更好的压缩。这会影响截图文件大小和写截图的时间。过高的压缩可能会占用过多的CPU时间并中断播放。默认值为7。
screenshot-jpeg-quality=&lt;0-100&gt; 设置 JPEG 质量级别。更高意味着更好的质量。默认值为 90。
参考 configuration-files screenshot ]]></content></entry><entry><title>Mpv快捷键</title><url>/posts/202211/mpv-keyboard/</url><categories><category>blog</category></categories><tags><tag>mpv</tag></tags><content type="html"><![CDATA[Seek backward/forward 5 seconds LEFT and RIGHT Seek backward/forward 5 seconds. Shift+arrow does a 1 second exact seek (see --hr-seek). Seek forward/backward 1 minute UP and DOWN Seek forward/backward 1 minute. Shift+arrow does a 5 second exact seek (see --hr-seek). Seek to the previous/next subtitle Ctrl+LEFT and Ctrl+RIGHT Seek to the previous/next subtitle. Subject to some restrictions and might not always work; see sub-seek command. Adjust subtitle delay Ctrl+Shift+Left and Ctrl+Shift+Right Adjust subtitle delay so that the next or previous subtitle is displayed now. This is especially useful to sync subtitles to audio. Decrease/increase speed by 10% [ and ] Decrease/increase current playback speed by 10%. Halve/double speed { and } Halve/double current playback speed. Reset speed BACKSPACE Reset playback speed to normal. Undo the last seek Shift+BACKSPACE Undo the last seek. This works only if the playlist entry was not changed. Hitting it a second time will go back to the original position. See revert-seek command for details. Mark the current position Shift+Ctrl+BACKSPACE Mark the current position. This will then be used by Shift+BACKSPACE as revert position (once you seek back, the marker will be reset). You can use this to seek around in the file and then return to the exact position where you left off. backward/forward playlist &lt; and &gt; Go backward/forward in the playlist. Go forward playlist. ENTER Go forward in the playlist. Pause p / SPACE Pause (pressing again unpauses). Step forward. . Step forward. Pressing once will pause, every consecutive press will play one frame and then go into pause mode again. Step backward , Step backward. Pressing once will pause, every consecutive press will play one frame in reverse and then go into pause mode again. quit q Stop playing and quit. Q Like q, but store the current playback position. Playing the same file later will resume at the old playback position if possible. Decrease/increase volume / and * Decrease/increase volume. 9 and 0 Decrease/increase volume. Mute m Mute sound. Cycle play _ Cycle through the available video tracks. # Cycle through the available audio tracks. fullscreen f Toggle fullscreen (see also &ndash;fs).
Exit fullscreen ESC Exit fullscreen mode. stay-on-top T Toggle stay-on-top (see also --ontop). Decrease/increase pan-and-scan w and W Decrease/increase pan-and-scan range. The e key does the same as W currently, but use is discouraged. Show progression bar o (also P) Show progression bar, elapsed time and total duration on the OSD. Toggle OSD states O Toggle OSD states between normal and playback time/duration. Toggle subtitle v Toggle subtitle visibility. Cycle through the available subtitles j and J Cycle through the available subtitles. Adjust subtitle delay z and Z Adjust subtitle delay by +/- 0.1 seconds. The x key does the same as Z currently, but use is discouraged. Set/clear loop points l Set/clear A-B loop points. See ab-loop command for details. infinite looping L Toggle infinite looping. Adjust audio delay Ctrl + and Ctrl - Adjust audio delay (A/V sync) by +/- 0.1 seconds. Adjust subtitle font size Shift+g and Shift+f Adjust subtitle font size by +/- 10%. subtitles ass overrides u Switch between applying no style overrides to SSA/ASS subtitles, and overriding them almost completely with the normal subtitle style. See --sub-ass-override for more info. subtitle VSFilter aspect compatibility mode V Toggle subtitle VSFilter aspect compatibility mode. See --sub-ass-vsfilter-aspect-compat for more info. Move subtitles up/down r and R Move subtitles up/down. The t key does the same as R currently, but use is discouraged. screenshot s Take a screenshot. S Take a screenshot, without subtitles. (Whether this works depends on VO driver support.) Ctrl s Take a screenshot, as the window shows it (with subtitles, OSD, and scaled video). Seek to the beginning of the previous/next chapter PGUP and PGDWN Seek to the beginning of the previous/next chapter. In most cases, &quot;previous&quot; will actually go to the beginning of the current chapter; see --chapter-seek-threshold. Seek backward or forward by 10 minutes Shift+PGUP and Shift+PGDWN Seek backward or forward by 10 minutes. (This used to be mapped to PGUP/PGDWN without Shift.) Activate/deactivate deinterlacer d Activate/deactivate deinterlacer. Cycle aspect ratio A Cycle aspect ratio override. hardware video decoding Ctrl h Toggle hardware video decoding on/off. Move the video rectangle Alt+LEFT, Alt+RIGHT, Alt+UP, Alt+DOWN Move the video rectangle (panning). changes video zoom Alt + and Alt - Combining Alt with the + or - keys changes video zoom. Reset pan/zoom Alt+BACKSPACE Reset the pan/zoom settings. Show the playlist F8 Show the playlist and the current position in it (useful only if a UI window is used, broken on the terminal). Show the list of audio and subtitle streams F9 Show the list of audio and subtitle streams (useful only if a UI window is used, broken on the terminal). displaying statistics i and I Show/toggle an overlay displaying statistics about the currently playing file such as codec, framerate, number of dropped frames and so on. See STATS for more information. Cycle OSC del Cycle OSC visibility between never / auto (mouse-move) / always Show console ` Show the console. (ESC closes it again. See CONSOLE.) ref mpv manual ]]></content></entry><entry><title>关于我</title><url>/about.html</url><categories/><tags/><content type="html">#TODO</content></entry><entry><title>Docker Command</title><url>/posts/202107/docker-command/</url><categories/><tags/><content type="html"><![CDATA[run v2ray under docker docker run &ndash;restart=always &ndash;network host -d &ndash;name v2ray -v ~/etc/v2ray:/etc/v2ray v2fly/v2fly-core v2ray &ndash;config=/etc/v2ray/config.json
]]></content></entry><entry><title>初始化pi4环境</title><url>/posts/202107/init-pi4-env/</url><categories/><tags/><content type="html">更新环境 sudo apt update sudo apt upgrade
安装docker Add Docker’s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg set up the stable repository echo &amp;#34;deb [arch=arm64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) stable&amp;#34; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null Install Docker Engine sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 配置docker权限 创建 docker 组(可选，nano中已包含docker组) 将当前用户添加到 docker 组中 激活组变化 sudo groupadd docker sudo usermod -aG docker $USER newgrp docker install frpc create frpc.ini file sudo mkdir /etc/frp cd /etc/frp sudo nano frpc.ini add under line:
[common] server_addr = xxx.xx.xx.xx server_port = 7000 [pi-CM4-IO-POE-BOX-B-test] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6981 start frpc docker run --restart=always --network host -d -v /etc/frp/frpc.ini:/etc/frp/frpc.ini --name frpc snowdreamtech/frpc install golang sudo tar -C /usr/local -xzf go1.16.5.linux-arm64.tar.gz 添加下面语句到.profile中
export PATH=$PATH:/usr/local/go/bin</content></entry><entry><title>分析Ubuntu Arm64 Docker Build</title><url>/posts/202011/how-to-build-ubuntu-arm64-docker/</url><categories/><tags/><content type="html">Ubuntu的Arm64 Docker Image项目在： docker-brew-ubuntu-core 该项目需要配合 Jenkins pipe line 文件执行。
文件首先删除 docker-brew-ubuntu-core 工程的对应arm64分支dist-amd64，并重新创建该分支，在该分支各ubuntu版本下创建Dockerfile，下载构造文件并归档到git仓库。
具体参考： docker-brew-ubuntu-core 最后，docker下官方提供的arm64的资源在 arm64v8 用户下。
另一个优质的docker arm资源在 balena.io ,项目地址在 balena-io-library jetson-xavier</content></entry><entry><title>在Pi4上编译ffmpeg支持硬件编解码以及测试和使用方法</title><url>/posts/202011/build-ffmpeg-under-pi4/</url><categories/><tags/><content type="html"><![CDATA[由于某些原因，需要在raspberry pi 4上编译最新版本ffmpeg，下面是方法以及测试方案。
编译准备 sudo apt update sudo apt upgrade 安装必要的工具和库 sudo apt install build-essential yasm pkg-config libx264-dev 下载源代码并编译 # 下载并解压 wget http://ffmpeg.org/releases/ffmpeg-snapshot-git.tar.bz2 tar jxvf ffmpeg-snapshot-git.tar.bz2 cd ffmpeg # 切换到明确的tag并创建分支 git checkout tags/n4.3.1 -b b4.3.1 ./configure --enable-gpl --enable-libx264 --enable-mmal --enable-omx --enable-omx-rpi ## pi4 2G上大约需要14分钟左右，请注意cpu散热 make -j4 sudo make install 测试rtsp h.264，1080p的cpu解码，并每5s保存一张图片 ffmpeg -rtsp_transport tcp -nostdin -loglevel error -i rtsp://username:password@ip -filter:v fps=fps=1/5 test_%03d.jpg 通过 bcmstat 软件观察，cpu消耗每路17%,内存消耗较少，约60MB。
测试rtsp h.264，1080p硬解，并每5s保存一张图片 首先需要配置GPU内存到300MB左右，默认76MB，配置路径为：Start-&gt;Preferences-&gt;Raspberry Pi Configuration-&gt;Performance-&gt;GPU Memory
ffmpeg -c:v h264_mmal -rtsp_transport tcp -nostdin -loglevel error -i rtsp://username:password@ip -filter:v fps=fps=1/5 test_%03d.jpg 通过 bcmstat 软件观察，cpu消耗一路9%左右，内存消耗也需要60MB，另外需要GPU mem约94MB。
注:使用GPU硬解码两路时，cpu上升到28%左右，内存和gpu内存也等比上升。
结论 使用pi的h264硬件解码时，除GPU额外内存消耗较大外，节省的cpu使用率也很少。当然，目前仅进行了ffmpeg的测试，并未通过其他软件来证实是芯片自生问题还是ffmpeg硬件解码算法问题。建议大家使用ffmpeg解码时，仅进行一路硬解。
参考 Compile FFmpeg for Ubuntu, Debian, or Mint Hardware Encoding with the Raspberry Pi ]]></content></entry><entry><title>Raspberry PI4环境初始化</title><url>/posts/202011/init-pi4/</url><categories/><tags/><content type="html"><![CDATA[pi 4准备 安装最新的pi镜像: 2020-08-20-raspios-buster-armhf 配置apt代理 sudo nano /etc/apt/apt.conf 添加下面语句到文件中：其中如果代理不需要登陆。username:password@可省略；ip和port请按照实际情况填写。
Acquire::http::Proxy &#34;http://username:password@ip:port&#34;; 更新操作系统到最新 sudo apt update sudo apt upgrade 安装bcmstat bcmstat 可以检测到如下指标：
CPU fequencies (ARM, Core, H264, V3D, ISP) Temperature (current and peak) for Core and/or PMIC IRQ/s Network Rx/Tx System utilisation (percentage user, nice, idle etc.) CPU load (including individual cores when available) GPU mem usage RAM usage (with/without swap) Memory leak detection (D/A options - instantaneous and accumulated memory deltas) Undervoltage, ARM frequency cap and temperature throttle event monitoring Customisable columns
安装方式：
curl -Ls https://raw.githubusercontent.com/MilhouseVH/bcmstat/master/bcmstat.sh -o ~/bin/bcmstat.sh chmod +x ~/bin/bcmstat.sh 添加环境变量到.profile，logout再login
export PATH=$PATH:~/bin 添加一个默认配置文件
echo &#34;xgd10&#34; &gt;&gt; ~/.bcmstat.conf 安装golang 下载 go1.15.5.linux-armv6l 执行下面命令：
sudo tar -C /usr/local -xzf go1.15.5.linux-armv6l.tar.gz 添加下面语句到.profile中
export PATH=$PATH:/usr/local/go/bin ]]></content></entry><entry><title>列举pip可安装组件的版本信息</title><url>/posts/202011/pip-list-all-versions-of-package/</url><categories/><tags/><content type="html">方法1 在需要安装组件名称后添加==符号，pip会自动列举可安装版本信息。
输入：
pip3 install pyqt5== 得到：
Could not find a version that satisfies the requirement pyqt5== (from versions: 5.14.0, 5.14.1, 5.14.2, 5.15.0, 5.15.1) 其他方法参考 Python and pip, list all versions of a package that&amp;rsquo;s available</content></entry><entry><title>使用CrowdHuman训练Yolov4</title><url>/posts/202011/use-crowd-human-trainning-yolov4/</url><categories/><tags/><content type="html">本文介绍在agx上使用旷视CrowdHuman库训练yoloV4模型。
数据准备 git clone https://github.com/jkjung-avt/yolov4_crowdhuman cd yolov4_crowdhuman/data ./prepare_data.sh 960x960 在agx上训练 git clone https://github.com/AlexeyAB/darknet.git</content></entry><entry><title>AI库</title><url>/posts/202011/ai-datasets/</url><categories/><tags/><content type="html">旷视人脸，人头,人脸，身体库 CrowdHuman is a benchmark dataset to better evaluate detectors in crowd scenarios. The CrowdHuman dataset is large, rich-annotated and contains high diversity. CrowdHuman contains 15000, 4370 and 5000 images for training, validation, and testing, respectively. There are a total of 470K human instances from train and validation subsets and 23 persons per image, with various kinds of occlusions in the dataset. Each human instance is annotated with a head bounding-box, human visible-region bounding-box and human full-body bounding-box. We hope our dataset will serve as a solid baseline and help promote future research in human detection tasks.
WIDER FACE人脸数据库 WIDER FACE dataset is a face detection benchmark dataset, of which images are selected from the publicly available WIDER dataset. We choose 32,203 images and label 393,703 faces with a high degree of variability in scale, pose and occlusion as depicted in the sample images. WIDER FACE dataset is organized based on 61 event classes. For each event class, we randomly select 40%/10%/50% data as training, validation and testing sets. We adopt the same evaluation metric employed in the PASCAL VOC dataset. Similar to MALF and Caltech datasets, we do not release bounding box ground truth for the test images. Users are required to submit final prediction files, which we shall proceed to evaluate.
kitti KITTI Vision Benchmark Suite .We take advantage of our autonomous driving platform Annieway to develop novel challenging real-world computer vision benchmarks. Our tasks of interest are: stereo, optical flow, visual odometry, 3D object detection and 3D tracking. For this purpose, we equipped a standard station wagon with two high-resolution color and grayscale video cameras. Accurate ground truth is provided by a Velodyne laser scanner and a GPS localization system. Our datsets are captured by driving around the mid-size city of Karlsruhe, in rural areas and on highways. Up to 15 cars and 30 pedestrians are visible per image. Besides providing all data in raw format, we extract benchmarks for each task. For each of our benchmarks, we also provide an evaluation metric and this evaluation website. Preliminary experiments show that methods ranking high on established benchmarks such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias and complement existing benchmarks by providing real-world benchmarks with novel difficulties to the community.
pascal VOC pascal VOC VOC2012: 20 classes. The train/val data has 11,530 images containing 27,450 ROI annotated objects and 6,929 segmentations.Size of segmentation dataset substantially increased. People in action classification dataset are additionally annotated with a reference point on the body.
image-net image-net academictorrents academictorrents 支持对现有开放ai资源库的搜索和基于BitTorrents协议的下载服务的网站。</content></entry><entry><title>人体姿势识别</title><url>/posts/202011/pose-of-person/</url><categories/><tags/><content type="html">本文尝试运行trt_pose项目。
安装依赖 安装PyTorch和Torchvision, 参见 安装Pytorch和Torchvision 安装 torch2trt git clone https://github.com/NVIDIA-AI-IOT/torch2trt cd torch2trt sudo python3 setup.py install --plugins 安装其它依赖 sudo pip3 install tqdm cython pycocotools sudo apt-get install python3-matplotlib 安装trt_pose git clone https://github.com/NVIDIA-AI-IOT/trt_pose cd trt_pose sudo python3 setup.py install 安装jetcam jetcam是一个jetson下操作usb和csi摄像头的库。
jetcam运行依赖模块traitlets，需先安装traitlets。
sudo pip3 install traitlets 然后安装jetcam
git clone https://github.com/NVIDIA-AI-IOT/jetcam cd jetcam sudo python3 setup.py install 运行示例 1import time 2 3t0 = time.time() 4torch.cuda.current_stream().synchronize() 5for i in range(50): 6 y = model_trt(data) 7 8torch.cuda.current_stream().synchronize() 9t1 = time.time() 10 11print(50.0 / (t1 - t0)) 参考 trt_pose</content></entry><entry><title>Hello Jetson Inference</title><url>/posts/202011/hello-jetson-inference/</url><categories/><tags/><content type="html">本文尝试运行Hello AI World,Hello AI World 主要包括：图像分类、物体识别、图像分割。
Jetson nano安装JetPack 略，参见 Jetson Nano环境初始化 编译项目 更新系统，并安装必要的工具
sudo apt update sudo apt upgrade sudo apt install git cmake libpython3-dev python3-numpy clone项目并进行编译，中间会提示下载模型，可以直接点击ok，下载默认的几个模型
git clone --recursive https://github.com/dusty-nv/jetson-inference cd jetson-inference mkdir build cd build cmake ../ make -j$(nproc) sudo make install sudo ldconfig pytorch的安装，参见 安装Pytorch和Torchvision 验证 切换到jetson-inference工程编译目录的bin目录下：
cd jetson-inference/build/aarch64/bin 图像分类 首次运行命令，TensorRT会花费较长时间进行网络优化，优化后的网络文件会缓存在磁盘上，下次运行直接加载优化后的模型。
# C++ ./imagenet images/orange_0.jpg images/test/output_0.jpg # Python ./imagenet.py images/orange_0.jpg images/test/output_0.jpg # C++ ./imagenet images/strawberry_0.jpg images/test/output_1.jpg # Python ./imagenet.py images/strawberry_0.jpg images/test/output_1.jpg 可以使用--network关键字指定使用什么网络，默认未指定系统默认使用googlenet：
# C++ ./imagenet --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg # Python ./imagenet.py --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg # C++ ./imagenet --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg # Python ./imagenet.py --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg 项目支持的完整的模型列表参见： Classifying Images with ImageNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./imagenet rtsp://admin:123456@192.168.1.26 物体识别 首次运行命令，TensorRT会花费较长时间进行网络优化，优化后的网络文件会缓存在磁盘上，下次运行直接加载优化后的模型。
# C++ ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output_peds_0.jpg # Python ./detectnet.py --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output_peds_0.jpg # C++ ./detectnet images/peds_1.jpg images/test/output_peds_1.jpg # Python ./detectnet.py images/peds_1.jpg images/test/output_peds_1.jpg 项目支持的完整的模型列表参见： Locating Objects with DetectNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./detectnet rtsp://admin:123456@192.168.1.26 图像分割 # C++ ./segnet --network=fcn-resnet18-cityscapes images/city_0.jpg images/test/output_city_0.jpg # Python ./segnet.py --network=fcn-resnet18-cityscapes images/city_0.jpg images/test/output_city_0.jpg # C++ ./segnet --network=fcn-resnet18-deepscene images/trail_0.jpg images/test/output_trail_0.jpg # C++ ./segnet --network=fcn-resnet18-deepscene --visualize=mask images/trail_0.jpg images/test/output_mask_trail_0.jpg # C++ ./segnet --network=fcn-resnet18-mhp images/humans_0.jpg images/test/output_humans_0.jpg # Python ./segnet.py --network=fcn-resnet18-mhp images/humans_0.jpg images/test/output_humans_0.jpg 项目支持的完整的模型列表参见： Semantic Segmentation with SegNet 检测rtsp流:(这里的admin:123456为摄像头的用户名和密码，请根据实际情况填写用户名、密码和IP地址)
./segnet --network=fcn-resnet18-deepscene rtsp://admin:Zyx123456@192.168.1.26 参见 Hello AI World Building the Project from Source Classifying Images with ImageNet Locating Objects with DetectNet Semantic Segmentation with SegNet</content></entry><entry><title>安装Pytorch和Torchvision</title><url>/posts/202011/install-pytorch-torchvision/</url><categories/><tags/><content type="html"><![CDATA[本文简单描述在jetson nano上安装最新的pytorch 1.7.0和torchvision 0.8.1的步骤。
安装 安装前准备 sudo apt update sudo apt upgrade 安装pytorch 首先下载最新的pytorch版本 PyTorch v1.7.0 ，下载后得到文件torch-1.7.0-cp36-cp36m-linux_aarch64.whl.
sudo sudo apt-get install python3-pip libopenblas-base libopenmpi-dev pip3 install Cython pip3 install numpy torch-1.7.0-cp36-cp36m-linux_aarch64.whl 安装torchvision sudo apt-get install libjpeg-dev zlib1g-dev git clone --branch v0.8.1 https://github.com/pytorch/vision torchvision cd torchvision export BUILD_VERSION=0.8.1 sudo python3 setup.py install ## 这步需要编译，时间较长 校验 运行python3
import torch print(torch.__version__) print(&#39;CUDA available: &#39; + str(torch.cuda.is_available())) print(&#39;cuDNN version: &#39; + str(torch.backends.cudnn.version())) a = torch.cuda.FloatTensor(2).zero_() print(&#39;Tensor a = &#39; + str(a)) b = torch.randn(2).cuda() print(&#39;Tensor b = &#39; + str(b)) c = a + b print(&#39;Tensor c = &#39; + str(c)) import torchvision print(torchvision.__version__) python3交互式控制台会输出类似下面的语句：
1.7.0 CUDA available: True cuDNN version: 8000 Tensor a = tensor([0., 0.], device=&#39;cuda:0&#39;) Tensor b = tensor([ 0.3777, -0.5432], device=&#39;cuda:0&#39;) Tensor c = tensor([ 0.3777, -0.5432], device=&#39;cuda:0&#39;) 0.8.0a0+45f960c 参考 pytorch for jetson ]]></content></entry><entry><title>编译最新opencv 4.4.0 with cuda</title><url>/posts/202011/build-opencv-with-cuda/</url><categories/><tags/><content type="html">本文介绍如何在nano/agx上编译opencv 4.4.0 with cuda.
步骤 该库在原有库基础上做了一些调整，原有库在nano上只能单线程运行。需要原有库的同学参见参考连接。
# clone the repository git clone https://github.com/peace0phmind/nano_build_opencv.git cd nano_build_opencv ./build_opencv.sh 参考 nano_build_opencv</content></entry><entry><title>Ubuntu使用Mac键盘</title><url>/posts/202011/ubuntu-use-mac-keyboard/</url><categories/><tags/><content type="html">介绍如何在ubuntu下使用mac键盘。
由于长期使用mac的缘故，对command按键的使用非常顺手，又由于需要使用blender软件，所以购买了Keychron K4的带数字键的机械硬盘，后来发现这个键盘虽然可以完成blender中的一些视图切换，但在截屏方面非常不方便（没有Print Screen按键）,建议有和我同样诉求的购买全尺寸键盘。
打开settings的界面，在Region &amp;amp; Language中找到Input Sources，点击下面的+号，在出现的列表中选择English(Macintosh)。
具体可以参考下面参考章节中的图片，但不要选择图片中的输入方式，图片中的输入方式会导致Shift + 3的组合键输出的是£而不是期望的#。
参考： Using a UK mac keyboard on Ubuntu</content></entry><entry><title>Blender 2.8x快捷键</title><url>/posts/202011/blender-2.8x-shortcuts/</url><categories/><tags/><content type="html">本文主要记录 Blender 2.8x的快捷方式。
注：num_做前缀的按钮表示数字键盘区的按键，num_7表示的是数字小键盘7，其他对照类比。普通的按键7会直接用7标识。lmb表示鼠标左键，rmb表示鼠标右键，mmb表示鼠标中键。
设置单位 blender 2.82默认单位为m,需要设置为mm, Unit Scale需要甚至为0.001.
通用快捷键 shift-a show add menu(添加三维物体) shift-s-1 cursor to world origin（鼠标到世界原点） shift-s-2 cursor to selected（鼠标到选择点，物体的中心点） shift-s-3 cursor to active（鼠标到活动点） shift-s-4 cursor to gride（鼠标到网格） shift-s-6 selection to grid shift-s-7 selection to cursor (keep offset) shift-s-8 selection to cursor shift-s-9 selection to active x-d remove object（删除物体等） ctrl-lmb Lasso select: drag the mouse to form a freehand selection area.(选择物体等) 视角切换 num_7 Top View ctrl-num_7 Bottom View num_1 Front View ctrl-num_1 Back View num_3 Right View ctrl-num_3 Left View num_0 Camera View num_. Put select objects to the view center.(select object, move mouse to view, press num_. button)（将选择的所有物体放在视图正中间，有别于shift-c） shift-mmb move view 对象模式（已选择物体） tab Start/stop EditMode. alt-e. Start/stop EditMode. Alternative hotkey: tab. s size(scale) mode r rotate mode a select all aa deselect all home see all object in one view shift-c CentreZero View. The 3DCursor is set to zero (0,0,0) and the view is changed so that all Objects, including the 3Dcursor, can be displayed. This is an alternative for home.（将所有物体，包括的灯光和摄像头等都放置到视图正中间，并设置3d鼠标到原点） shift-d. Add Duplicate. The selected Objects are duplicated. Grab mode starts immediately thereafter. alt-g. Clears translations, given in Grab mode. The X,Y,Z locations of selected Objects are set to zero. alt-j. Join faces, selected triangular faces are joined in pairs and transformed to quads z-4 wireframe mode（线框模式） z-6 solid mode z-8 rendered mode z-2 material preview shift-z toggles shaded mode on/off(在线框和投影模式下切换) alt-z toggles textured mode on/off（在线框和纹理模式下切换） alt-s Clears size. The X,Y,Z dimensions of selected Objects are set to 1.0. ctrl-m mirror menu. alt-o Clear Origin. The ‘Origin’ is erased for all Child Objects, which causes the Child Objects to move to the exact location of the Parent Objects. m Moves selected Object(s) to another layer, a pop-up appers. g Grab Mode. g-x g-y g-z constrains movement to X, Y or Z axis of the global reference. 编辑模式（mesh） e extrude selected e-x e-y e-z constrains extrude selected to X, Y or Z axis of the global reference. a select all a-a deselect all alt-lmb select a collection of points f Make Edge/Face. If 2 vertices are selected, an edge is created. If 3 or 4 vertices are selected, a face is created. shift-f Fill selected. All selected vertices that are bound by edges and form a closed polygon are filled with triangular faces. Holes are automatically taken into account. This operation is 2D; various layers of polygons must be filled in succession. alt-f Beauty Fill. The edges of all the selected triangular faces are switched in such a way that equally sized faces are formed. This operation is 2D; various layers of polygons must be filled in succession. The Beauty Fill can be performed immediately after a Fill. ctrl-f Flip faces, selected triangular faces are paired and common edge of each pair swapped. ctrl-r Face Loop Cut.Face loops are highlighted starting from edge under mouse pointer. alt-m select multiple points and merge them shift-c CentreZero View. The 3DCursor is set to zero (0,0,0) and the view is changed so that all Objects, including the 3Dcursor, can be displayed. This is an alternative for home. o Switch in/out of Proportional Editing. shift-g Select Similar ctrl-e edge menu.(include bridge edge loops)(对数量相等的两条边进行自动全连接) shift-n and shift-ctrl-n recalculate the normals of selected faces(重新计算法线) ctrl-b bevel tool 参考 Blender HotKeys In-depth Reference blender-2-8-where-is-the-remove-doubles blender-2-8-for-architecture</content></entry><entry><title>常用命令与工具</title><url>/posts/202010/usage-commands/</url><categories/><tags/><content type="html">类似mac airdrop的工具 这里强烈推荐一个类似mac下airdrop的网站, https://snapdrop.net 这个网站可以让使用同一局域网的所有设备（jetson agx/nano, raspberry pi, windows, linux_x86, phone etc.）相互快速共享文件或发送消息。(使用时请关闭代理，否则无法正确找到对方)
用浏览器打开即可看到自己的名字，每次刷新名字随机产生。点击对方头像可以选择文件，拖动文件到头像也可以进行文件分享。在头像上点击右键，弹出框中输入需要发送的消息。
还有个 https://www.sharedrop.io ，不过这个网站用的缓存服务器需要代理才可以访问，不是很方便。
清除DNS缓存 ubuntu操作系统使用如下命令：
sudo systemd-resolve --flush-caches 参考： How to clear DNS cache 获取不同网络环境下的ping值，DNS解析结果等 https://www.boce.com</content></entry><entry><title>调整内存使用</title><url>/posts/202010/tuning-memory-usage/</url><categories/><tags/><content type="html">nano分4G版和2G版。其SD镜像分别为： 4G版 ， 2G版 。
4G和2G内存版本的主要区别在于启动后的桌面，2G内存版考虑到内存少的情况，启用的是LXDE的桌面。（切换到level 3后, 4G版镜像比2G版镜像多0.1G，jtop观察前者0.4G,后者0.3G）
禁用桌面GUI 考虑到nano的内存紧缺，如果不是直接在nano上进行GUI开发调试，那么会考虑使用level 3的方式启动nano。禁用桌面可以节省(Unity/GNOME 大概 800MB, LXDE可以节省大概250MB）内存。
禁用桌面
sudo init 3 启用桌面
sudo init 5 如果希望修改系统默认启动行为，则输入如下命令：
默认启动到控制台界面(level 3)：
sudo systemctl set-default multi-user.target 默认启动到图形界面(level 5):
sudo systemctl set-default graphical.target 创建swap文件(可选) 2G版本nano在启动配置时可以选择添加swap，也可以使用jtop工具通过界面配置swap文件的启用和大小。
此处给出手动创建和启用swap文件的方法： 假设需要创建4GB swap文件：
sudo fallocate -l 4G /mnt/4GB.swap sudo mkswap /mnt/4GB.swap sudo swapon /mnt/4GB.swap 将下面行添加到/etc/fstab文件中
/mnt/4GB.swap none swap sw 0 0 创建swap分区(可选) 通过disks工具在磁盘上创建一个单独的分区，假设新建分区/dev/sda1
sudo mkswap /dev/sda1 # get the new partition id: xxx-xxx-xxx sudo blkid /dev/sda1 # write config to file echo &amp;#34;xxx-xxx-xxx none swap sw 0 0&amp;#34; | sudo tee -a /etc/fstab 重新启动操作系统。
参考 How to Add a Swap Partition on Jetson TX1 How do I add swap after system installation?</content></entry><entry><title>Jetson Nano环境初始化</title><url>/posts/202010/nano-env-init/</url><categories/><tags/><content type="html"><![CDATA[本文主要介绍Jetson Nano启动后环境的准备工作. TF卡flush以及系统启动初始化 下载并烧录最新的TF卡镜像 4G内存版 ; 2G内存版 。完成nvidia的一系列初始化操作（协议，时区配置，账号信息配置等）。
Ubuntu 系统的更新 sudo apt update sudo apt upgrade sudo apt dist-upgrade sudo apt autoremove 安装ohmyzsh 个人比较喜欢ohmyzsh下的一些快捷输入和操作方式。 由于墙的存在，直接安装会失败，可以手动安装
首先需要安装zsh
sudo apt install zsh -y 手动安装ohmyzsh
# Clone the repository git clone https://github.com/ohmyzsh/ohmyzsh.git ~/.oh-my-zsh # Optionally, backup your existing ~/.zshrc file cp ~/.zshrc ~/.zshrc.orig # Create a new zsh configuration file cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc # Change your default shell chsh -s $(which zsh) 安装ohmyzsh的zsh-autosuggestions插件 zsh-autosuggestions插件支持超棒的历史命令联想功能。
# Clone this repository into $ZSH_CUSTOM/plugins (by default ~/.oh-my-zsh/custom/plugins) git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions # Add the plugin to the list of plugins for Oh My Zsh to load (inside ~/.zshrc): plugins=(zsh-autosuggestions) # Start a new terminal session. 安装jdk sudo apt install openjdk-8-jdk -y 安装terminator terminator是ubuntu下比较美观，且支持分屏的工具。其可以类比为mac下的iterm2。
sudo apt install terminator -y 安装pip3 sudo apt install python3-pip -y 安装jtop jtop可以用来显示系统资源使用情况，比如：查看cpu，内存，gpu使用情况；查看安装的库的信息；控制风扇启用和转速等。
sudo -H pip3 install -U jetson-stats sudo systemctl restart jetson_stats.service 使用前还需要logout或者reboot
使用jtop启用jetson_clocks 在不启用jetson_clocks时，jetson的cpu和gpu的主频是根据需要动态变化的，且如果支持PWM的风扇默认也是不工作的（Fan转速为0，如果是普通的3pin风扇则会持续稳定运行。只有4pin的调速风扇会受到jetson_clocks的影响控制转速）。建议启用jetson_clocks，将主频固定下来。在GUI界面，未启用jetson_clocks时会有卡顿的现象。
输入jtop启动jtop，按5进入控制界面：
点击system按钮，启用Fan转速的Auto模式 点击jetson_clocks左边的s按钮，启动jetson_clocks 点击boot左边的e，设置jetson_clocks系统启动自动运行 安装golang环境 从 golang下载页面 下载最新的 go1.15.3.linux-arm64安装包 执行下面命令安装golang到/usr/local目录下:
sudo tar -C /usr/local -xzf go1.15.3.linux-arm64.tar.gz 将/usr/local/go/bin目录添加到PATH环境变量，参见
export PATH=$PATH:/usr/local/go/bin:$HOME/go/bin 安装curl curl 支持 http, https, socks4, socks5 代理 wget 支持 http, https 代理
而socks5支持dns代理，可以解决一些dns污染的问题
sudo apt install curl -y 配置nvcc环境变量 拷贝下面代码到.bashrc或.zshrc文件(如果你安装使用了zsh)，或者.profile或.zprofile文件。 关于 .*rc和.*profile文件的使用说明参见 export PATH=/usr/local/cuda/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH 配置docker权限 创建 docker 组(可选，nano中已包含docker组) 将当前用户添加到 docker 组中 激活组变化 sudo groupadd docker sudo usermod -aG docker $USER newgrp docker 当激活了组变化后，执行docker ps 可以看到docker命令正确执行。
配置docker registry mirrors 配置docker registry mirrors可以进行docker pull加速，解决docker pull缓慢的问题。
使用编辑器打开/etc/docker/daemon.json文件，按json格式添加如下内容：
&#34;registry-mirrors&#34;: [&#34;https://registry.docker-cn.com&#34;] 此处url也可使用阿里云的个人docker加速器，例如：https://xxxxx.mirror.aliyuncs.com，这里 xxxx参见 添加完后，daemon.json文件内容类似如下：
{ &#34;runtimes&#34;: { &#34;nvidia&#34;: { &#34;path&#34;: &#34;nvidia-container-runtime&#34;, &#34;runtimeArgs&#34;: [] } }, &#34;registry-mirrors&#34;: [&#34;https://7s7m9b11.mirror.aliyuncs.com&#34;] } 安装 docker-compose sudo apt install docker-compose -y 安装右键resize image工具 sudo apt install nautilus-image-converter 上面命令安装完成后，执行下面命令重启nautilus
nautilus -q ]]></content></entry><entry><title>AGX添加nvme ssd并设置从ssd启动</title><url>/posts/202010/add-nvme-ssd/</url><categories/><tags/><content type="html">AGX出厂自带32G EMMC，并自带Ubuntu 18.04 + JetPack 4.4。本文对EMMC进行了磁盘读写的测试，并且对AGX进行改装，分别测试加装了海康的1T nvme ssd硬盘和SAMSUNG 1T nvme ssd，并进行了对比测试。最后简单介绍了了如何将AGX的默认启动方式修改为从nvme的ssd启动。
磁盘读写性能测试方式 使用linux下的dd进行磁盘读写性能测试。
测试磁盘写速度 sync; dd if=/dev/zero of=tempfile bs=1M count=1024; sync 测试磁盘读速度 dd if=tempfile of=/dev/null bs=1M count=1024 清理读缓存 sudo /sbin/sysctl -w vm.drop_caches=3 emmc性能测试 emmc写盘和覆盖写 emmc写盘1.4 GB/s(实际测试结果输出后，该民令并没有立即结束，所以这里的数据并不能用于参考) emmc覆盖写的速度大概在119 MB/s emmc缓存读和直接读的速度 emmc缓存读的速度很高，在7.7GB/s左右 emmc直接读取的速度很低，在307 MB/s左右 SamSung 1T SSD性能测试 SamSung写盘和覆盖写 SamSung写盘1.3 GB/s SamSung覆盖写的速度大概在897 MB/s SamSung缓存读和直接读的速度 SamSung缓存读的速度很高，在7.1GB/s左右 SamSung直接读取的速度很低，在1.7 GB/s左右 HikVision 1T SSD性能测试 HikVision写盘和覆盖写 HikVision写盘1.3 GB/s HikVision覆盖写的速度大概在992 MB/s HikVision缓存读和直接读的速度 HikVision缓存读的速度很高，在7.9GB/s左右 1.HikVision直接读取的速度很低，在1.6 GB/s左右 对比 HikVision 1T和SamSung 1T的性能相近，价格前者8百不到，后者1200左右，相差400左右，我先买了HikVision后购买并替换为了SamSung的ssd，下面介绍下原因：
先看下两个ssd的照片对比，上面为HikVison，下面为SamSung：
正面对比，差别不大 背面对比：从背面看SamSung的背面没有元器件，Hikision的有很多细小密集的元器件。 从HikVision装配图来看,背面有元器件会导致整个ssd中间突起。 替换下来的HikVision，已经有轻微变形了。 从SamSung装配图来看,背面没有元器件会非常贴合Agx的PCI-E接口。 修改启动盘，从ssd启动 完成物理装配后开机 在Disks工具中找到1T SSD，点击小齿轮，对整个磁盘进行format创建一个大分区（有别于参考中，还要预留16G空间，此处使用完整空间）。完成format后，保持磁盘在unmount状态。 打开命令行，执行下面命令：（注： 在我的disks中，我的磁盘名称为/dev/nvme0n1，而不是参考中的/dev/nvme0n1p1，可能与我使用的jetpack 4.4.1有关，所以我修改了代码以保证程序可以运行） # clone the repository: git clone https://github.com/peace0phmind/rootOnNVMe.git # switch to that repository&amp;#39;s directory cd rootOnNVMe # copy the rootfs of the eMMC card to the SSD ./copy-rootfs-ssd.sh # Finally, we will add a service which will run a script when the system starts up. ./setup-service.sh 参考 Install NVMe SSD on NVIDIA Jetson AGX Developer Kit Jetson Xavier NX – Run from SSD</content></entry><entry><title>Agx开箱</title><url>/posts/202010/get-and-assemble-agx/</url><categories/><tags/><content type="html">经过20天漫长的等待，终于在某个星期日收到了包裹。
包裹看上去挺大的。 拆开后AGX的盒子大概这么大，图的上方是我的Mac book pro,可以对比参考下大小。 打开盒子，AGX实际只有盒子大小的1/4，就只中间一块，保护的很好。 AGX的实际大小差不多是一个PCI-E插槽的大小。 电源插头不是国标的，毕竟是海外购，能够理解，自己的家里找了个电源线插上，没有的话可以上某宝购买，几块钱还包邮。 接上显示器，键盘鼠标等设备，开机即可进入系统（中间License选择界面和初始化配置界面按提示操作）。（AGX内置了一块32G的eMMC,默认预装Ubuntu 18.04） 由于AGX接口太少(一个HDMI， 2个type-c，一个E-SATA接口，一个micro-usb)，所以测试了一下外接华为扩展坞，支持双屏显示，扩展网口等。上图我插上了USB的键盘和无线鼠标。</content></entry><entry><title>开篇</title><url>/posts/202010/my-first-post/</url><categories/><tags/><content type="html">9月份某个星期六，加班到恨晚考虑到第二天还要到公司，于是将电脑放在了窗边的工位上。第二天一场大雨把我2013年下半年购买的顶配（习惯购买默认出厂顶配，非定制机型）Mac Book Pro泡在了水里。屏幕被烧坏，但机器加电连接外接显示器依然可以正常工作，不得不佩服苹果的做工扎实。吃饭的家伙没有了，得赶紧整一个，否则耽误项目进度，于是有了下面的折腾之旅。
按理说我是标准的“Apple Fans”，电脑坏了会第一时间考虑购买苹果的最新款顶配Mac Book Pro，那我为啥还要折腾呢？
我的Mac Book Pro是最后一代采用nvidia显卡的苹果笔记本，可以说是绝版nvidia+apple的配置，后面的mac book电脑都无法跑cuda，当年在自己的笔记本上给小伙伴演示使用cuda加速tf，而其他人都只能跑在linux系统上，这种独特的感觉在在现在的苹果电脑上找不到了。 作为一个优秀的打字员，学会的第一个技能就是盲打（不看键盘打字），紧接着的第二个技能就是熟记大部分常用软件的快捷键，第三个技能就是手速快，配合上快捷键，那屏幕上翻飞的窗口，别人看了就是一种艺术的享受。自从mac有了bar&amp;hellip;，关键bar还替换了常用的一些F1-12，切换不同窗口上下文得看到bar变化后再去点击&amp;hellip;。可以说bar就不是为我等优秀打字员设计的。对于熟记快捷键的我来说，bar就是一个摆设，为没用的东西花上3000快，不值！！！ 苹果我只崇拜2个人，Jobs于2011年10月去世了；苹果首席设计师乔纳森·艾维（Jony Ive）从Jobs去世的那年开始就风闻计划离开苹果，终于在去年某天离开了苹果。从2012年到现在，苹果除了换换配置，更新更新周边，系统升级下皮肤，几乎就没有以前那种令人惊艳的创新的产品面试（那个bar真不算，那个是设计上的倒退，对于我来说；也有人说窄边框，但窄边框真不是苹果首先搞出来的）。缺少了这两位的苹果，已经从一个伟大的公司变成了一个只考虑如何赚钱的，搞办公室文化的体量很大的公司。可以说，2013年前，还有很多技术是苹果首次采用和创新的，之后就真的没有什么能够吸引我注意的产品了。 随着虚拟化，k8s等技术得到极大的运用，作为优秀打字员的我也希望在本地好好玩玩这些技术，所以我需要一个32-64G内存，1T硬盘的笔记本，可惜我苹果顶配只有16G内存。7年了，16G内存还是16G内存，没有发生过变化。有人有不同观点，说32G内存普通人用不上；其实我想说，最用不上的更新是CPU，我就打打字，你说CPU能有多少占用？还每年百分之多少提升，给我打字员用就是浪费。如今的Raspberry Pi 3B都够用（当然排除喝咖啡时间，当然现在技术都先进了，都在云端和咖啡了，及其CPU也就本地喝咖啡用用，没啥强烈诉求了）。按照摩尔定律6年了，内存少说应该上到64G而且价格不变，考虑到用户用不上这么多内存，配置32G内存的电脑价格应该还要有下降。看看苹果定制机型，32G版本的配置足够我买其它品牌相同配置的2个。 介于苹果已经走下神坛；介于库克把我崇拜的Ive排挤出了公司；介于苹果没有创新的点吸引到我花多一倍的钱购买，苹果的选项被我划掉了。
市面上标配32G内存的电脑真的太少，太贵了。出厂默认32G内存的笔记本电脑型号很少，且其16G机型和32G机型相差很多，有些小伙伴都是买16G机型自己回来自己加上一个16G的。这个选项我也考虑过，但是没有选到好看的机器（可以自己加内存的笔记本，都比较厚重&amp;hellip;），所以这个只是待选项，继续寻找中。
在上Nvidia网站找东西的时候，无意间发现我关注的Jetson AGX出32G版本的了(记得刚出来的时候是16G的把，当时Mac正常工作，没有考虑过，所以可能记错了)，一个想法跃然脑中，使用AGX作开发电脑！！！
在对比了某宝价格和amazon海外购，决定在amazon上进行海外购，给国家多贡献点自己的力量。
于是果断出手购买了一个Huawei 16G的最新笔记本先用着。才4K多的价格，相对于类似配置的苹果来说，那真的是白菜价了。
下面，即将开启AGX折腾之旅。</content></entry></search>